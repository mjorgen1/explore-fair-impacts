{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import packages and set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# imports for my own code\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import choices\n",
    "from scipy import stats\n",
    "\n",
    "# import all of our files\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import Liu_paper_code.fico as fico\n",
    "import Liu_paper_code.distribution_to_loans_outcomes as dlo\n",
    "\n",
    "from scripts.data_creation_utils import get_pmf,get_repay_probabilities,get_scores, adjust_set_ratios\n",
    "from scripts.evaluation_utils import inspect_MinMax\n",
    "from scripts.visualization_utils import visualize_data_distribution, visual_scores_by_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_dir = '../data/raw/'\n",
    "results_dir = '../data/testing/'\n",
    "file_name = 'test.csv'\n",
    "\n",
    "set_size = 100000\n",
    "order_of_magnitude = 100000 # amount of samples generated in a batch; larger than set_size\n",
    "\n",
    "group_size_ratio = [0.12,0.88]\n",
    "black_label_ratio = [0.66,0.34]\n",
    "\n",
    "shuffle_seed = 42\n",
    "round_num_scores = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and parse the data\n",
    "#### Code is primarily from Lydia's FICO-figures.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cdfs, performance, totals = fico.get_FICO_data(data_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert the data into format needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = all_cdfs[[\"White\",\"Black\"]]\n",
    "\n",
    "# B is White\n",
    "# A is Black\n",
    "\n",
    "cdf_B = cdfs['White'].values\n",
    "cdf_A = cdfs['Black'].values\n",
    "\n",
    "repay_B = performance['White']\n",
    "repay_A = performance['Black']\n",
    "scores = cdfs.index\n",
    "scores_list = scores.tolist()\n",
    "scores_repay = cdfs.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters\n",
    "N_scores = cdf_B.size\n",
    "N_groups = 2\n",
    "\n",
    "# get probability mass functions of each group\n",
    "pi_A = get_pmf(cdf_A)\n",
    "pi_B = get_pmf(cdf_B)\n",
    "pis = np.vstack([pi_A, pi_B])\n",
    "\n",
    "# demographic statistics \n",
    "#group_ratio = np.array((totals[\"Black\"], totals[\"White\"]))\n",
    "#group_size_ratio = group_ratio/group_ratio.sum() - true fico data goup size ratio\n",
    "#print(group_size_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get loan repay probabilities for a given score\n",
    "loan_repaid_probs = [lambda i: repay_A[scores[scores.get_loc(i,method='nearest')]], \n",
    "                     lambda i: repay_B[scores[scores.get_loc(i,method='nearest')]]]\n",
    "\n",
    "# unpacking repay probability as a function of score\n",
    "loan_repay_fns = [lambda x: loan_repaid_prob(x) for\n",
    "                      loan_repaid_prob in loan_repaid_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make repay probabilities into percentages from decimals\n",
    "scores_arr = np.asarray(get_scores(scores=scores_list, round_num=round_num_scores)) # we recommend 1 or 2 for round_num\n",
    "print(scores_arr)\n",
    "repay_A_arr = pd.Series.to_numpy(repay_A)*100\n",
    "repay_B_arr = pd.Series.to_numpy(repay_B)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sample from the data according to ratios and combine the scores and probabilities and convert data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data according to the pmf\n",
    "def sample(group_size_ratio, order_of_magnitude, shuffle_seed,scores_arr, pi_A, pi_B, repay_A_arr, repay_B_arr):\n",
    "    \n",
    "    # Sample data according to the pmf\n",
    "    # Reference: https://www.w3schools.com/python/ref_random_choices.asp\n",
    "\n",
    "    num_A_samples = int(group_size_ratio[0] * order_of_magnitude)\n",
    "    num_B_samples = int(group_size_ratio[1] * order_of_magnitude)\n",
    "\n",
    "    samples_A = np.asarray(sorted(choices(scores_arr, pi_A, k=num_A_samples)))\n",
    "    samples_B = np.asarray(sorted(choices(scores_arr, pi_B, k=num_B_samples)))\n",
    "\n",
    "    # Calculate samples groups' probabilities and make arrays for race\n",
    "\n",
    "    # A == Black == 0 (later defined as 0.0 when converting to pandas df)\n",
    "    samples_A_probs = get_repay_probabilities(samples=samples_A,scores_arr=scores_arr, repay_probs=repay_A_arr, round_num=1)\n",
    "    samples_A_race = np.zeros(num_A_samples, dtype= int)\n",
    "    # B == White == 1 (later defined as 1.0 when converting to pandas df)\n",
    "    samples_B_probs = get_repay_probabilities(samples=samples_B,scores_arr=scores_arr, repay_probs=repay_B_arr, round_num=1)\n",
    "    samples_B_race = np.ones(num_B_samples, dtype= int)\n",
    "\n",
    "    # Get data in dict form with score and repay prob\n",
    "    data_A_dict = {'score': samples_A, 'repay_probability': samples_A_probs} #,'race': samples_A_race}\n",
    "    data_B_dict = {'score': samples_B, 'repay_probability': samples_B_probs} #,'race': samples_B_race}\n",
    "\n",
    "    # Get data in dict form with score, repay prob, and race\n",
    "    data_A_dict = {'score': samples_A, 'repay_probability': samples_A_probs ,'race': samples_A_race}\n",
    "    data_B_dict = {'score': samples_B, 'repay_probability': samples_B_probs,'race': samples_B_race}\n",
    "\n",
    "    # Convert from dict to df\n",
    "    data_A_df = pd.DataFrame(data=data_A_dict, dtype=np.float64)\n",
    "    data_B_df = pd.DataFrame(data=data_B_dict, dtype=np.float64)\n",
    "\n",
    "    # Combine all of the data together and shuffle\n",
    "    # NOTE: not currently being used but could be useful at a later time\n",
    "    data_all_df = pd.concat([data_A_df, data_B_df], ignore_index=True)\n",
    "    #print(data_all_df)\n",
    "    np.random.seed(shuffle_seed)\n",
    "    data_all_df_shuffled = data_all_df.sample(frac=1).reset_index(drop=True)\n",
    "    #print(data_all_df_shuffled)\n",
    "\n",
    "    # Add Final Column to dataframe, repay indices\n",
    "    # repay: 1.0, default: 0.0\n",
    "    probabilities = data_all_df_shuffled['repay_probability']\n",
    "    repay_indices = []\n",
    "    # Create a random num and then have that decide given a prob if the person gets a loan or not\n",
    "    # (e.g. If 80% prob, then calculate a random num, then if that is below they will get loan, if above, then they don't)\n",
    "\n",
    "    for index, prob in enumerate(probabilities):\n",
    "        rand_num = random.randint(0,1000)/10\n",
    "        if rand_num > prob:  # default\n",
    "            repay_indices.append(0)\n",
    "        else:\n",
    "            repay_indices.append(1)  # repay\n",
    "\n",
    "    data_all_df_shuffled['repay_indices'] = np.array(repay_indices)\n",
    "\n",
    "    return data_all_df_shuffled, samples_A, samples_B, samples_A_probs, samples_B_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Generate set, based on set-ratios specified in Section 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.w3schools.com/python/ref_random_choices.asp\n",
    "# Calculate samples groups' probabilities and make arrays for race\n",
    "# A == Black == 0 (later defined as 0.0 when converting to pandas df)\n",
    "# B == White == 1 (later defined as 1.0 when converting to pandas df)\n",
    "\n",
    "# generate first batch of samples:\n",
    "data,samples_A, samples_B, samples_A_probs, samples_B_probs = sample(group_size_ratio, order_of_magnitude,shuffle_seed, scores_arr, pi_A, pi_B, repay_A_arr, repay_B_arr)\n",
    "# split the data cols (x,y)\n",
    "x = data[['score','repay_probability', 'race']].values\n",
    "y = data['repay_indices'].values\n",
    "\n",
    "# adjust the set according to the ratios specified\n",
    "x,y = adjust_set_ratios(x, y, black_label_ratio, group_size_ratio, set_size)\n",
    "i = 0\n",
    "# if dataset it to small, samplee a larger batch\n",
    "while len(y) < set_size:\n",
    "    i += 1\n",
    "    # Generate new samples\n",
    "    data_add, samples_A_add, samples_B_add, samples_A_probs_add, samples_B_probs_add = sample(group_size_ratio, order_of_magnitude,i, scores_arr, pi_A, pi_B, repay_A_arr, repay_B_arr)\n",
    "    data = pd.concat([data,data_add])\n",
    "    samples_A = np.concatenate((samples_A,samples_A_add))\n",
    "    samples_A_probs = np.concatenate((samples_A_probs,samples_A_probs_add))\n",
    "    samples_B = np.concatenate((samples_B,samples_B_add))\n",
    "    samples_B_probs = np.concatenate((samples_B_probs,samples_B_probs_add))\n",
    "    # split the data cols (x,y)\n",
    "    x = data[['score','repay_probability', 'race']].values\n",
    "    y = data['repay_indices'].values\n",
    "\n",
    "    # adjust the set according to the ratios specified\n",
    "    x,y = adjust_set_ratios(x,y, black_label_ratio, group_size_ratio, set_size)\n",
    "\n",
    "# merge x,y back into a DataFrame\n",
    "df = {'score':x[:,0],'repay_probability': x[:,1],'race':x[:,2],'repay_indices': y}\n",
    "data = pd.DataFrame(df)\n",
    "\n",
    "# print proportions of dataset\n",
    "idx_An = np.where((x[:, 2] == 0) & (y == 0))[0]\n",
    "idx_Ap = np.where((x[:, 2] == 0) & (y == 1))[0]\n",
    "idx_B = np.where((x[:, 2] == 1))[0]\n",
    "print(i,'Black N/P:',len(idx_An),'/',len(idx_Ap),'White:',len(idx_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save the pandas dataframes to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(index=False, path_or_buf=results_dir+file_name)\n",
    "\n",
    "# To save the data separately by race\n",
    "#data_A_df.to_csv(index=False, path_or_buf='simData_2decProbs_0decScores_groupA_black.csv')\n",
    "#data_B_df.to_csv(index=False, path_or_buf='simData_2decProbs_0decScores_groupB_white.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Inspect the min/max values of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_MinMax(samples_A_probs,samples_B_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualize Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_data_distribution(results_dir,samples_A,samples_A_probs,samples_B,samples_B_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual_scores_by_race(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
