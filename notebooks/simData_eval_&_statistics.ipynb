{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/results/synthetic_test1/00/'\n",
    "folders= ['dt','gnb','lgr','gbt']\n",
    "#folders= ['dt','gnb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_csvs(data_path= 'data/results/',b_or_w = 'Black', folders= ['dt','gnb','lgr','gbt']):\n",
    "\n",
    "    col_names_eg = []\n",
    "    col_names_gs = []\n",
    "\n",
    "    for i,f in enumerate(folders):\n",
    "        if b_or_w == 'Black':\n",
    "            path = f'{data_path}{f}/{f}_black_results.csv'\n",
    "        else:\n",
    "            path = f'{data_path}{f}/{f}_white_results.csv'\n",
    "\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        col_names_eg.append(f'EG+{f.upper()}')\n",
    "        col_names_gs.append(f'GS+{f.upper()}')\n",
    "\n",
    "        if i == 0:\n",
    "            joined_df = df.iloc[:,-1]\n",
    "        else:\n",
    "            joined_df = pd.concat([joined_df, df.iloc[:,-1]], axis=1)\n",
    "\n",
    "    joined_df.set_axis(folders, axis=1)\n",
    "\n",
    "\n",
    "    # split dataframe after the two reduction algorithms\n",
    "    df_eg = joined_df.iloc[:6,:]\n",
    "    df_gs = pd.concat([joined_df.iloc[0:1,:],joined_df.iloc[6:,:]])\n",
    "\n",
    "    # set new index\n",
    "    df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_eg.set_index('Constraint',inplace=True)\n",
    "    df_gs['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_gs.set_index('Constraint',inplace=True)\n",
    "    df_eg.columns = col_names_eg\n",
    "    df_gs.columns = col_names_gs\n",
    "\n",
    "    df_final = pd.concat([df_eg, df_gs], axis=1)\n",
    "    print('Group: ',b_or_w,'\\n DataFrame: \\n',df_final)\n",
    "    print('A')\n",
    "    df_final.to_csv(f'{data_path}/{b_or_w}_DI.csv')\n",
    "    print('B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  Black \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated  19.29    0.00   19.15   19.24  19.29    0.00   19.15   19.24\n",
      "DP          -10.73   -5.95  -11.89  -10.42  -2.49   -9.38   -1.28    1.96\n",
      "EO           13.60   10.82   12.52   15.18  19.29  -21.46   19.15   19.24\n",
      "EOO           6.90    2.08    4.74    7.36  16.24   19.15   12.76   16.24\n",
      "FPER         13.69    7.58   13.45   15.21  19.29    0.00   19.15   19.24\n",
      "ERP          19.29   19.24   19.09   19.30  19.29   16.05   19.15   19.24\n",
      "A\n",
      "B\n",
      "Group:  White \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated   9.12    3.17    7.78    9.12   9.12    3.17    7.78    9.12\n",
      "DP           10.76   15.38   10.20   11.94  10.76   11.16    9.77    9.77\n",
      "EO           11.21    6.78    9.27   12.92   9.12   19.34    7.78    9.12\n",
      "EOO          12.53   10.02   11.66   12.68   9.77    6.61    8.78    9.77\n",
      "FPER         10.76    9.92    9.89   12.53   9.12    3.17    7.78    9.12\n",
      "ERP           6.90   13.49    7.07   11.60   9.12    3.91    7.78    9.12\n",
      "A\n",
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_16996\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_16996\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n"
     ]
    }
   ],
   "source": [
    "impact_csvs(data_path,'Black', folders= ['dt','gnb','lgr','gbt'])\n",
    "impact_csvs(data_path,'White', folders= ['dt','gnb','lgr','gbt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FP/TP/TN/FN Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.016  0.032  0.067  0.053   0.138   0.048    0.068    0.032   \n",
      "FP        0.323  0.144  0.120  0.132   0.047   0.165    0.119    0.144   \n",
      "TN        0.177  0.356  0.380  0.368   0.453   0.335    0.381    0.356   \n",
      "TP        0.484  0.468  0.433  0.447   0.362   0.452    0.432    0.468   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.046    0.033  0.031  0.032  0.138  0.028   0.138   0.028   \n",
      "FP          0.177    0.132  0.248  0.144  0.047  0.157   0.047   0.157   \n",
      "TN          0.323    0.368  0.252  0.356  0.453  0.343   0.453   0.343   \n",
      "TP          0.454    0.467  0.469  0.468  0.362  0.472   0.362   0.472   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.138    0.028    0.075    0.030    0.0    0.0   0.138   0.028  \n",
      "FP          0.047    0.157    0.099    0.152    0.0    0.0   0.047   0.157  \n",
      "TN          0.453    0.343    0.401    0.348    0.5    0.5   0.453   0.343  \n",
      "TP          0.362    0.472    0.425    0.470    0.5    0.5   0.362   0.472  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.084  0.065  0.067  0.063   0.148   0.061    0.115    0.026   \n",
      "FP        0.312  0.097  0.149  0.156   0.043   0.112    0.138    0.152   \n",
      "TN        0.188  0.403  0.351  0.344   0.457   0.388    0.362    0.348   \n",
      "TP        0.416  0.435  0.433  0.437   0.352   0.439    0.385    0.474   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.038    0.034  0.017  0.031    0.0  0.079   0.242   0.017   \n",
      "FP          0.212    0.148  0.303  0.142    0.5  0.063   0.017   0.198   \n",
      "TN          0.288    0.352  0.197  0.358    0.0  0.437   0.483   0.302   \n",
      "TP          0.462    0.466  0.483  0.469    0.5  0.421   0.258   0.483   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN            0.5    0.016    0.150    0.020    0.0    0.0     0.5   0.016  \n",
      "FP            0.0    0.203    0.042    0.178    0.0    0.0     0.0   0.203  \n",
      "TN            0.5    0.297    0.458    0.322    0.5    0.5     0.5   0.297  \n",
      "TP            0.0    0.484    0.350    0.480    0.5    0.5     0.0   0.484  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.013  0.030  0.061  0.053   0.150   0.053    0.064    0.030   \n",
      "FP        0.329  0.149  0.131  0.143   0.042   0.158    0.123    0.151   \n",
      "TN        0.171  0.351  0.369  0.357   0.458   0.342    0.377    0.349   \n",
      "TP        0.487  0.470  0.439  0.447   0.350   0.447    0.436    0.470   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.046    0.032  0.031  0.030  0.150  0.025   0.150   0.025   \n",
      "FP          0.190    0.138  0.238  0.152  0.042  0.167   0.042   0.167   \n",
      "TN          0.310    0.362  0.262  0.348  0.458  0.333   0.458   0.333   \n",
      "TP          0.454    0.468  0.469  0.470  0.350  0.475   0.350   0.475   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.150    0.025    0.064    0.026    0.0    0.0   0.150   0.025  \n",
      "FP          0.042    0.167    0.127    0.160    0.0    0.0   0.042   0.167  \n",
      "TN          0.458    0.333    0.373    0.340    0.5    0.5   0.458   0.333  \n",
      "TP          0.350    0.475    0.436    0.474    0.5    0.5   0.350   0.475  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.014  0.033  0.071  0.061   0.138   0.050    0.071    0.033   \n",
      "FP        0.319  0.136  0.108  0.118   0.047   0.133    0.107    0.132   \n",
      "TN        0.181  0.364  0.392  0.382   0.453   0.367    0.393    0.368   \n",
      "TP        0.486  0.467  0.429  0.439   0.362   0.450    0.429    0.467   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.048    0.033  0.036  0.030  0.131  0.028   0.131   0.028   \n",
      "FP          0.172    0.131  0.215  0.152  0.051  0.157   0.051   0.157   \n",
      "TN          0.328    0.369  0.285  0.348  0.449  0.343   0.449   0.343   \n",
      "TP          0.452    0.467  0.464  0.470  0.369  0.472   0.369   0.472   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.131    0.028    0.075    0.030    0.0    0.0   0.131   0.028  \n",
      "FP          0.051    0.157    0.099    0.152    0.0    0.0   0.051   0.157  \n",
      "TN          0.449    0.343    0.401    0.348    0.5    0.5   0.449   0.343  \n",
      "TP          0.369    0.472    0.425    0.470    0.5    0.5   0.369   0.472  \n"
     ]
    }
   ],
   "source": [
    "# Ratios\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts(normalize=True)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Ratio'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Ratio']\n",
    "    df = df.fillna(0)\n",
    "    df = df.round(decimals = 3)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN          38.0    77.0   163.0   129.0   334.0   116.0    164.0     77.0   \n",
      "FP         781.0   349.0   291.0   319.0   114.0   399.0    289.0    349.0   \n",
      "TN         429.0   861.0   919.0   891.0  1096.0   811.0    921.0    861.0   \n",
      "TP        1172.0  1133.0  1047.0  1081.0   876.0  1094.0   1046.0   1133.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          111.0     80.0    75.0    77.0   334.0    68.0   334.0    68.0   \n",
      "FP          428.0    319.0   601.0   349.0   114.0   380.0   114.0   380.0   \n",
      "TN          782.0    891.0   609.0   861.0  1096.0   830.0  1096.0   830.0   \n",
      "TP         1099.0   1130.0  1135.0  1133.0   876.0  1142.0   876.0  1142.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          334.0     68.0    182.0     73.0     0.0     0.0   334.0    68.0  \n",
      "FP          114.0    380.0    239.0    367.0     0.0     0.0   114.0   380.0  \n",
      "TN         1096.0    830.0    971.0    843.0  1210.0  1210.0  1096.0   830.0  \n",
      "TP          876.0   1142.0   1028.0   1137.0  1210.0  1210.0   876.0  1142.0  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         204.0   158.0   163.0   153.0   357.0   147.0    278.0     64.0   \n",
      "FP         756.0   234.0   361.0   378.0   103.0   272.0    333.0    369.0   \n",
      "TN         454.0   976.0   849.0   832.0  1107.0   938.0    877.0    841.0   \n",
      "TP        1006.0  1052.0  1047.0  1057.0   853.0  1063.0    932.0   1146.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN           93.0     83.0    40.0    74.0     0.0   192.0   586.0    40.0   \n",
      "FP          512.0    358.0   734.0   344.0  1210.0   153.0    40.0   478.0   \n",
      "TN          698.0    852.0   476.0   866.0     0.0  1057.0  1170.0   732.0   \n",
      "TP         1117.0   1127.0  1170.0  1136.0  1210.0  1018.0   624.0  1170.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN         1210.0     38.0    362.0     49.0     0.0     0.0  1210.0    38.0  \n",
      "FP            0.0    491.0    102.0    430.0     0.0     0.0     0.0   491.0  \n",
      "TN         1210.0    719.0   1108.0    780.0  1210.0  1210.0  1210.0   719.0  \n",
      "TP            0.0   1172.0    848.0   1161.0  1210.0  1210.0     0.0  1172.0  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN          31.0    73.0   148.0   129.0   364.0   128.0    154.0     73.0   \n",
      "FP         795.0   360.0   316.0   347.0   102.0   383.0    298.0    365.0   \n",
      "TN         415.0   850.0   894.0   863.0  1108.0   827.0    912.0    845.0   \n",
      "TP        1179.0  1137.0  1062.0  1081.0   846.0  1082.0   1056.0   1137.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          111.0     78.0    75.0    73.0   362.0    61.0   362.0    61.0   \n",
      "FP          460.0    334.0   575.0   367.0   102.0   405.0   102.0   405.0   \n",
      "TN          750.0    876.0   635.0   843.0  1108.0   805.0  1108.0   805.0   \n",
      "TP         1099.0   1132.0  1135.0  1137.0   848.0  1149.0   848.0  1149.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          362.0     61.0    156.0     63.0     0.0     0.0   362.0    61.0  \n",
      "FP          102.0    405.0    308.0    388.0     0.0     0.0   102.0   405.0  \n",
      "TN         1108.0    805.0    902.0    822.0  1210.0  1210.0  1108.0   805.0  \n",
      "TP          848.0   1149.0   1054.0   1147.0  1210.0  1210.0   848.0  1149.0  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN          33.0    79.0   172.0   147.0   333.0   120.0    173.0     80.0   \n",
      "FP         773.0   329.0   261.0   286.0   114.0   323.0    260.0    319.0   \n",
      "TN         437.0   881.0   949.0   924.0  1096.0   887.0    950.0    891.0   \n",
      "TP        1177.0  1131.0  1038.0  1063.0   877.0  1090.0   1037.0   1130.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          115.0     81.0    87.0    73.0   317.0    68.0   317.0    68.0   \n",
      "FP          416.0    316.0   520.0   367.0   123.0   380.0   123.0   380.0   \n",
      "TN          794.0    894.0   690.0   843.0  1087.0   830.0  1087.0   830.0   \n",
      "TP         1095.0   1129.0  1123.0  1137.0   893.0  1142.0   893.0  1142.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          317.0     68.0    182.0     73.0     0.0     0.0   317.0    68.0  \n",
      "FP          123.0    380.0    239.0    367.0     0.0     0.0   123.0   380.0  \n",
      "TN         1087.0    830.0    971.0    843.0  1210.0  1210.0  1087.0   830.0  \n",
      "TP          893.0   1142.0   1028.0   1137.0  1210.0  1210.0   893.0  1142.0  \n"
     ]
    }
   ],
   "source": [
    "# Absolute numbers\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts()\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Number'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Number']\n",
    "    df = df.fillna(0)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_absolute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractig Scores from csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      testB  testW  unmitB  unmitW  egdpB  egdpW  egeoB  egeoW  egtprpB  \\\n",
      "0       731    722     806     797    806    797    806    797      806   \n",
      "1       468    750     468     825    318    825    468    825      468   \n",
      "2       355    549     355     549    355    549    355    549      355   \n",
      "3       390    495     390     495    390    495    390    495      390   \n",
      "4       434    620     434     695    300    695    434    695      300   \n",
      "...     ...    ...     ...     ...    ...    ...    ...    ...      ...   \n",
      "2415    537    406     537     406    612    406    612    406      612   \n",
      "2416    684    416     759     416    759    416    759    416      759   \n",
      "2417    755    475     830     475    830    475    830    475      830   \n",
      "2418    706    620     781     470    781    470    781    470      781   \n",
      "2419    601    312     676     312    676    312    676    312      676   \n",
      "\n",
      "      egtprpW  egfprpB  egfprpW  egerpB  egerpW  gsdpB  gsdpW  gseoB  gseoW  \\\n",
      "0         797      806      797     806     797    806    797    806    797   \n",
      "1         825      468      825     468     825    318    825    468    825   \n",
      "2         549      355      549     355     549    355    549    355    549   \n",
      "3         495      390      495     390     495    390    495    390    495   \n",
      "4         695      434      695     434     695    300    695    434    695   \n",
      "...       ...      ...      ...     ...     ...    ...    ...    ...    ...   \n",
      "2415      406      612      406     537     406    612    406    537    406   \n",
      "2416      416      759      416     759     416    759    416    759    416   \n",
      "2417      475      830      475     830     475    830    475    830    475   \n",
      "2418      470      781      470     781     470    781    470    781    470   \n",
      "2419      312      676      312     676     312    676    312    676    312   \n",
      "\n",
      "      gstprpB  gstprpW  gsfprpB  gsfprpW  gserpB  gserpW  \n",
      "0         806      797      806      797     806     797  \n",
      "1         468      825      468      825     468     825  \n",
      "2         355      549      355      549     355     549  \n",
      "3         390      495      390      495     390     495  \n",
      "4         434      695      434      695     434     695  \n",
      "...       ...      ...      ...      ...     ...     ...  \n",
      "2415      612      406      537      406     537     406  \n",
      "2416      759      416      759      416     759     416  \n",
      "2417      830      475      830      475     830     475  \n",
      "2418      781      470      781      470     781     470  \n",
      "2419      676      312      676      312     676     312  \n",
      "\n",
      "[2420 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scores Data Frames\n",
    "classifier_dfs = {}\n",
    "dfs_b = {}\n",
    "dfs_w = {}\n",
    "dfs_eg = {}\n",
    "dfs_gs = {}\n",
    "for f in folders:\n",
    "    path = f'{data_path}{f}/{f}_all_scores.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    df_black = df.filter(like='B')\n",
    "    df_white = df.filter(like='W')\n",
    "    df_eg = pd.concat([df.iloc[:,:4],df.filter(like='eg')],axis=1)\n",
    "    df_gs = pd.concat([df.iloc[:,:4],df.filter(like='gs')],axis=1)\n",
    "    \n",
    "    classifier_dfs[f] = df\n",
    "    dfs_b[f] = df_black\n",
    "    dfs_w[f] = df_white\n",
    "    dfs_eg[f] = df_eg\n",
    "    dfs_gs[f] = df_gs\n",
    "print(classifier_dfs['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if normal distributions:\n",
    "\n",
    "if p < 0.01 (or < 0.05) then the distribution is significantly different from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dt\n",
      "Check for norm Distributions done\n",
      "Classifier: gnb\n",
      "Check for norm Distributions done\n",
      "Classifier: lgr\n",
      "Check for norm Distributions done\n",
      "Classifier: gbt\n",
      "Check for norm Distributions done\n"
     ]
    }
   ],
   "source": [
    "for c,df in classifier_dfs.items():\n",
    "    print('Classifier:',c)\n",
    "    for col in df:\n",
    "        data=df[col].dropna(axis=0)\n",
    "        _,p = stats.kstest(data, \"norm\")\n",
    "        if p > 0.01:\n",
    "            print(col,',p:',p)\n",
    "    print('Check for norm Distributions done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann Whitney U test:\n",
    "\n",
    "“a two-sample rank test for the difference between two population medians . . . It assumes that the data are independent random samples from two populations that have the same shape.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_path = f'{data_path}mwu/'\n",
    "os.makedirs(mwu_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions EG vs. GS\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dt gnb lgr gbt\n",
      "Constraints               \n",
      "stB                       \n",
      "stW                       \n",
      "mitB                      \n",
      "mitW                      \n",
      "dpB          s       s   s\n",
      "dpW                       \n",
      "eoB          s   s   s   s\n",
      "eoW              s        \n",
      "tprpB        s   s   s   s\n",
      "tprpW                     \n",
      "fprpB        s       s   s\n",
      "fprpW            s        \n",
      "erpB                      \n",
      "erpW             s        \n"
     ]
    }
   ],
   "source": [
    "p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "for (c1,df_eg),(c2,df_gs) in zip(dfs_eg.items(),dfs_gs.items()):\n",
    "    col_signi = []\n",
    "    col_vals = []\n",
    "    idx = []\n",
    "    \n",
    "    for col_eg,col_gs in zip(df_eg,df_gs):\n",
    "        \n",
    "        idx.append(col_eg[2:])\n",
    "        \n",
    "        data_eg=df_eg[col_eg].dropna(axis=0)\n",
    "        data_gs=df_gs[col_gs].dropna(axis=0)\n",
    "        \n",
    "        _,p = stats.mannwhitneyu(data_eg, data_gs)\n",
    "        \n",
    "        col_vals.append(p)\n",
    "        if p< 0.05:\n",
    "            col_signi.append('s')\n",
    "        else:\n",
    "            col_signi.append(' ')\n",
    "            \n",
    "    p_signi[c1] = col_signi\n",
    "    p_vals[c1] = col_vals\n",
    "    \n",
    "p_vals['Constraints'] = idx\n",
    "p_vals = p_vals.set_index('Constraints')\n",
    "p_signi['Constraints'] = idx\n",
    "p_signi = p_signi.set_index('Constraints')\n",
    "\n",
    "p_vals = p_vals.round(decimals=3)\n",
    "print(p_signi)\n",
    "    \n",
    "p_vals.to_csv(f'{mwu_path}p_eg_gs.csv')\n",
    "p_signi.to_csv(f'{mwu_path}significanz_eg_gs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions Each Model against each other\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_values_mwu_1model(dfs,model=''):\n",
    "    p_vals = pd.DataFrame(data={'Classifier': []})\n",
    "    p_signi = pd.DataFrame(data={'Classifier': []})\n",
    "    \n",
    "    for c1,df1 in dfs.items():\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data1 = df1[model].dropna(axis=0)\n",
    "        \n",
    "        for c2,df2 in dfs.items():\n",
    "            idx.append(c2)\n",
    "            \n",
    "            data2 =df2[model].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data1, data2)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c1] = col_signi\n",
    "        p_vals[c1] = col_vals\n",
    "        \n",
    "    p_vals['Classifier'] = idx\n",
    "    p_vals = p_vals.set_index('Classifier')\n",
    "    p_signi['Classifier'] = idx\n",
    "    p_signi = p_signi.set_index('Classifier')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_{model}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: testB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: testW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: unmitW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                     s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egtprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                     s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egtprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s    \n",
      "lgr             s        \n",
      "gbt                      \n",
      "\n",
      "C: gsdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gseoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gseoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gstprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gstprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gsfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: gserpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gserpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n"
     ]
    }
   ],
   "source": [
    "for col in classifier_dfs['dt']:\n",
    "    print('\\nC:',col)\n",
    "    p_values_mwu_1model(classifier_dfs,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions unmitigated v Mitigated for each race\n",
    "\n",
    "if p < 0.001 (or < 0.0005) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_race_mwu(dfs, b_or_w = 'B'):\n",
    "    p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "    p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "    for c,df in dfs.items():\n",
    "        \n",
    "        c = f'{c}{b_or_w}'\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data_unmiti = df[f'unmit{b_or_w}'].dropna(axis=0)\n",
    "        \n",
    "        for col in df:\n",
    "            \n",
    "            idx.append(col[:-1])\n",
    "            \n",
    "            data_miti=df[col].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data_unmiti, data_miti)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c] = col_signi\n",
    "        p_vals[c] = col_vals\n",
    "        \n",
    "    p_vals['Constraints'] = idx\n",
    "    p_vals = p_vals.set_index('Constraints')\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_signi['Constraints'] = idx\n",
    "    p_signi = p_signi.set_index('Constraints')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_un_vs_miti_{b_or_w}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_un_vs_miti_{b_or_w}.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:\n",
      "            dtB gnbB lgrB gbtB\n",
      "Constraints                   \n",
      "test          s         s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo          s         s    s\n",
      "egtprp        s         s    s\n",
      "egfprp        s         s    s\n",
      "egerp              s          \n",
      "gsdp          s    s    s    s\n",
      "gseo               s          \n",
      "gstprp        s    s    s    s\n",
      "gsfprp                        \n",
      "gserp              s          \n",
      "\n",
      "White:\n",
      "            dtW gnbW lgrW gbtW\n",
      "Constraints                   \n",
      "test          s         s    s\n",
      "unmit                         \n",
      "egdp               s          \n",
      "egeo                          \n",
      "egtprp             s          \n",
      "egfprp             s          \n",
      "egerp              s          \n",
      "gsdp               s          \n",
      "gseo               s          \n",
      "gstprp                        \n",
      "gsfprp                        \n",
      "gserp                         \n"
     ]
    }
   ],
   "source": [
    "print('Black:')\n",
    "p_race_mwu(dfs_b,'B')\n",
    "\n",
    "print('\\nWhite:')\n",
    "p_race_mwu(dfs_w,'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_unmiti' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stats\u001b[38;5;241m.\u001b[39mpearsonr(\u001b[43mdata_unmiti\u001b[49m, data_miti)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_unmiti' is not defined"
     ]
    }
   ],
   "source": [
    "stats.pearsonr(data_unmiti, data_miti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
