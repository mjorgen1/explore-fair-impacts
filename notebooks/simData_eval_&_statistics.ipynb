{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../results/synthetic_balTestSet/bb/'\n",
    "folders= ['dt','gnb','lgr','gbt']\n",
    "#folders= ['dt','gnb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_csvs(data_path= 'data/results/',b_or_w = 'Black', folders= ['dt','gnb','lgr','gbt']):\n",
    "\n",
    "    col_names_eg = []\n",
    "    col_names_gs = []\n",
    "\n",
    "    for i,f in enumerate(folders):\n",
    "        if b_or_w == 'Black':\n",
    "            path = f'{data_path}{f}/{f}_black_results.csv'\n",
    "        else:\n",
    "            path = f'{data_path}{f}/{f}_white_results.csv'\n",
    "\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        col_names_eg.append(f'EG+{f.upper()}')\n",
    "        col_names_gs.append(f'GS+{f.upper()}')\n",
    "\n",
    "        if i == 0:\n",
    "            joined_df = df.iloc[:,-1]\n",
    "        else:\n",
    "            joined_df = pd.concat([joined_df, df.iloc[:,-1]], axis=1)\n",
    "\n",
    "    joined_df.set_axis(folders, axis=1)\n",
    "\n",
    "\n",
    "    # split dataframe after the two reduction algorithms\n",
    "    df_eg = joined_df.iloc[:6,:]\n",
    "    df_gs = pd.concat([joined_df.iloc[0:1,:],joined_df.iloc[6:,:]])\n",
    "\n",
    "    # set new index\n",
    "    df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_eg.set_index('Constraint',inplace=True)\n",
    "    df_gs['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_gs.set_index('Constraint',inplace=True)\n",
    "    df_eg.columns = col_names_eg\n",
    "    df_gs.columns = col_names_gs\n",
    "\n",
    "    df_final = pd.concat([df_eg, df_gs], axis=1)\n",
    "    print('Group: ',b_or_w,'\\n DataFrame: \\n',df_final)\n",
    "    print('A')\n",
    "    df_final.to_csv(f'{data_path}/{b_or_w}_DI.csv')\n",
    "    print('B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  Black \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated  17.28   18.74   17.05   17.38  17.28   18.74   17.05   17.38\n",
      "DP            3.23    0.60    2.12    3.59  12.09   14.36    5.65   12.09\n",
      "EO           14.84   12.50   13.43   14.86  17.28   18.74   17.05   17.38\n",
      "EOO          13.77   11.78   11.92   13.91  12.62   12.87    7.56   12.09\n",
      "FPER         15.62   14.08   14.29   15.62  12.09   16.95   17.05   12.09\n",
      "ERP          17.28   18.29   17.09   17.38  17.28   18.84   17.38   17.38\n",
      "A\n",
      "B\n",
      "Group:  White \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated   9.58    2.08    8.45    9.11   9.58    2.08    8.45    9.11\n",
      "DP           17.68   16.52   17.57   18.05  16.05    9.94   15.82   16.55\n",
      "EO           13.95   12.13   12.49   13.63   9.58    2.08    8.45    9.11\n",
      "EOO          15.68   13.87   14.70   15.93  16.55   12.75   16.55   16.55\n",
      "FPER         13.78   12.88   13.04   14.00  14.91   11.25    8.45   14.91\n",
      "ERP           6.94    1.85    8.06    6.61   9.58   -8.72  -11.30    9.11\n",
      "A\n",
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_48052\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_48052\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n"
     ]
    }
   ],
   "source": [
    "impact_csvs(data_path,'Black', folders= ['dt','gnb','lgr','gbt'])\n",
    "impact_csvs(data_path,'White', folders= ['dt','gnb','lgr','gbt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FP/TP/TN/FN Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.038  0.072  0.069  0.056   0.086   0.045    0.071    0.038   \n",
      "FP        0.202  0.075  0.110  0.109   0.085   0.165    0.103    0.118   \n",
      "TN        0.298  0.425  0.390  0.391   0.415   0.335    0.397    0.382   \n",
      "TP        0.462  0.428  0.431  0.444   0.414   0.455    0.429    0.462   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.065    0.051  0.059  0.055  0.086  0.022   0.086   0.022   \n",
      "FP          0.118    0.099  0.133  0.095  0.085  0.154   0.085   0.154   \n",
      "TN          0.382    0.401  0.367  0.405  0.415  0.346   0.415   0.346   \n",
      "TP          0.435    0.449  0.441  0.445  0.414  0.478   0.414   0.478   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.059    0.045    0.061    0.058    0.0    0.0   0.086   0.022  \n",
      "FP          0.133    0.107    0.128    0.090    0.0    0.0   0.085   0.154  \n",
      "TN          0.367    0.393    0.372    0.410    0.5    0.5   0.415   0.346  \n",
      "TP          0.441    0.455    0.439    0.442    0.5    0.5   0.414   0.478  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.034  0.058  0.061  0.050   0.129   0.046    0.068    0.033   \n",
      "FP        0.222  0.090  0.129  0.124   0.057   0.195    0.115    0.127   \n",
      "TN        0.278  0.410  0.371  0.376   0.443   0.305    0.385    0.373   \n",
      "TP        0.466  0.442  0.439  0.450   0.371   0.454    0.432    0.467   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.058    0.046  0.066  0.023  0.134  0.013   0.131   0.008   \n",
      "FP          0.137    0.114  0.114  0.151  0.051  0.209   0.052   0.283   \n",
      "TN          0.363    0.386  0.386  0.349  0.449  0.291   0.448   0.217   \n",
      "TP          0.442    0.454  0.434  0.477  0.366  0.487   0.369   0.492   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.082    0.026    0.061    0.032    0.0    0.0   0.134   0.013  \n",
      "FP          0.089    0.141    0.126    0.128    0.0    0.0   0.051   0.209  \n",
      "TN          0.411    0.359    0.374    0.372    0.5    0.5   0.449   0.291  \n",
      "TP          0.418    0.474    0.439    0.468    0.5    0.5   0.366   0.487  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.037  0.066  0.063  0.051   0.086   0.051    0.067    0.034   \n",
      "FP        0.210  0.079  0.122  0.121   0.086   0.151    0.114    0.125   \n",
      "TN        0.290  0.421  0.378  0.379   0.414   0.349    0.386    0.375   \n",
      "TP        0.463  0.434  0.437  0.449   0.414   0.449    0.433    0.466   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.058    0.045  0.044  0.051  0.086  0.020   0.089   0.007   \n",
      "FP          0.134    0.109  0.183  0.098  0.086  0.163   0.082   0.301   \n",
      "TN          0.366    0.391  0.317  0.402  0.414  0.337   0.418   0.199   \n",
      "TP          0.442    0.455  0.456  0.449  0.414  0.480   0.411   0.493   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.086    0.020    0.050    0.058    0.0    0.0   0.086   0.020  \n",
      "FP          0.086    0.163    0.168    0.090    0.0    0.0   0.086   0.163  \n",
      "TN          0.414    0.337    0.332    0.410    0.5    0.5   0.414   0.337  \n",
      "TP          0.414    0.480    0.450    0.442    0.5    0.5   0.414   0.480  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.041  0.074  0.069  0.058   0.089   0.045    0.071    0.040   \n",
      "FP        0.199  0.072  0.110  0.111   0.082   0.168    0.103    0.116   \n",
      "TN        0.301  0.428  0.390  0.389   0.418   0.332    0.397    0.384   \n",
      "TP        0.459  0.426  0.431  0.442   0.411   0.455    0.429    0.460   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.065    0.052  0.059  0.058  0.089  0.021   0.089   0.021   \n",
      "FP          0.118    0.097  0.133  0.090  0.082  0.158   0.082   0.158   \n",
      "TN          0.382    0.403  0.367  0.410  0.418  0.342   0.418   0.342   \n",
      "TP          0.435    0.448  0.441  0.442  0.411  0.479   0.411   0.479   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.059    0.045    0.059    0.058    0.0    0.0   0.089   0.021  \n",
      "FP          0.133    0.107    0.133    0.090    0.0    0.0   0.082   0.158  \n",
      "TN          0.367    0.393    0.367    0.410    0.5    0.5   0.418   0.342  \n",
      "TP          0.441    0.455    0.441    0.442    0.5    0.5   0.411   0.479  \n"
     ]
    }
   ],
   "source": [
    "# Ratios\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts(normalize=True)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Ratio'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Ratio']\n",
    "    df = df.fillna(0)\n",
    "    df = df.round(decimals = 3)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         283.0   537.0   512.0   420.0   639.0   334.0    531.0    287.0   \n",
      "FP        1513.0   563.0   820.0   816.0   635.0  1236.0    772.0    882.0   \n",
      "TN        2223.0  3173.0  2916.0  2920.0  3101.0  2500.0   2964.0   2854.0   \n",
      "TP        3453.0  3199.0  3224.0  3316.0  3097.0  3402.0   3205.0   3449.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          489.0    380.0   440.0   409.0   639.0   164.0   639.0   164.0   \n",
      "FP          885.0    741.0   993.0   708.0   635.0  1153.0   635.0  1153.0   \n",
      "TN         2851.0   2995.0  2743.0  3028.0  3101.0  2583.0  3101.0  2583.0   \n",
      "TP         3247.0   3356.0  3296.0  3327.0  3097.0  3572.0  3097.0  3572.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          440.0    337.0    456.0    437.0     0.0     0.0   639.0   164.0  \n",
      "FP          993.0    801.0    959.0    669.0     0.0     0.0   635.0  1153.0  \n",
      "TN         2743.0   2935.0   2777.0   3067.0  3736.0  3736.0  3101.0  2583.0  \n",
      "TP         3296.0   3399.0   3280.0   3299.0  3736.0  3736.0  3097.0  3572.0  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         251.0   430.0   456.0   371.0   961.0   345.0    506.0    247.0   \n",
      "FP        1660.0   674.0   965.0   929.0   424.0  1458.0    861.0    947.0   \n",
      "TN        2076.0  3062.0  2771.0  2807.0  3312.0  2278.0   2875.0   2789.0   \n",
      "TP        3485.0  3306.0  3280.0  3365.0  2775.0  3391.0   3230.0   3489.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          435.0    345.0   492.0   174.0  1004.0    97.0   978.0    57.0   \n",
      "FP         1022.0    851.0   854.0  1130.0   380.0  1560.0   388.0  2118.0   \n",
      "TN         2714.0   2885.0  2882.0  2606.0  3356.0  2176.0  3348.0  1618.0   \n",
      "TP         3301.0   3391.0  3244.0  3562.0  2732.0  3639.0  2758.0  3679.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          612.0    197.0    459.0    242.0     0.0     0.0  1004.0    97.0  \n",
      "FP          665.0   1053.0    945.0    956.0     0.0     0.0   380.0  1560.0  \n",
      "TN         3071.0   2683.0   2791.0   2780.0  3736.0  3736.0  3356.0  2176.0  \n",
      "TP         3124.0   3539.0   3277.0   3494.0  3736.0  3736.0  2732.0  3639.0  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         278.0   496.0   469.0   379.0   640.0   382.0    497.0    253.0   \n",
      "FP        1571.0   589.0   912.0   904.0   644.0  1129.0    855.0    936.0   \n",
      "TN        2165.0  3147.0  2824.0  2832.0  3092.0  2607.0   2881.0   2800.0   \n",
      "TP        3458.0  3240.0  3267.0  3357.0  3096.0  3354.0   3239.0   3483.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          435.0    334.0   332.0   384.0   640.0   152.0   667.0    50.0   \n",
      "FP         1004.0    813.0  1368.0   732.0   646.0  1215.0   616.0  2250.0   \n",
      "TN         2732.0   2923.0  2368.0  3004.0  3090.0  2521.0  3120.0  1486.0   \n",
      "TP         3301.0   3402.0  3404.0  3352.0  3096.0  3584.0  3069.0  3686.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          640.0    152.0    370.0    437.0     0.0     0.0   640.0   152.0  \n",
      "FP          646.0   1215.0   1254.0    669.0     0.0     0.0   646.0  1215.0  \n",
      "TN         3090.0   2521.0   2482.0   3067.0  3736.0  3736.0  3090.0  2521.0  \n",
      "TP         3096.0   3584.0   3366.0   3299.0  3736.0  3736.0  3096.0  3584.0  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         303.0   552.0   512.0   433.0   667.0   335.0    531.0    301.0   \n",
      "FP        1485.0   537.0   819.0   827.0   616.0  1255.0    772.0    864.0   \n",
      "TN        2251.0  3199.0  2917.0  2909.0  3120.0  2481.0   2964.0   2872.0   \n",
      "TP        3433.0  3184.0  3224.0  3303.0  3069.0  3401.0   3205.0   3435.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          485.0    391.0   440.0   437.0   667.0   157.0   667.0   157.0   \n",
      "FP          880.0    723.0   993.0   669.0   616.0  1180.0   616.0  1180.0   \n",
      "TN         2856.0   3013.0  2743.0  3067.0  3120.0  2556.0  3120.0  2556.0   \n",
      "TP         3251.0   3345.0  3296.0  3299.0  3069.0  3579.0  3069.0  3579.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          440.0    337.0    440.0    437.0     0.0     0.0   667.0   157.0  \n",
      "FP          993.0    801.0    993.0    669.0     0.0     0.0   616.0  1180.0  \n",
      "TN         2743.0   2935.0   2743.0   3067.0  3736.0  3736.0  3120.0  2556.0  \n",
      "TP         3296.0   3399.0   3296.0   3299.0  3736.0  3736.0  3069.0  3579.0  \n"
     ]
    }
   ],
   "source": [
    "# Absolute numbers\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts()\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Number'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Number']\n",
    "    df = df.fillna(0)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_absolute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractig Scores from csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      testB  testW  unmitB  unmitW  egdpB  egdpW  egeoB  egeoW  egtprpB  \\\n",
      "0       750    837     825     850    825    850    825    837      825   \n",
      "1       647    782     722     850    722    850    722    782      722   \n",
      "2       508    605     508     455    508    605    508    455      508   \n",
      "3       444    348     444     348    444    348    444    348      444   \n",
      "4       767    701     842     776    842    776    842    776      842   \n",
      "...     ...    ...     ...     ...    ...    ...    ...    ...      ...   \n",
      "7467    658    562     733     412    733    562    733    412      733   \n",
      "7468    771    379     621     379    621    379    621    379      621   \n",
      "7469    565    505     640     505    640    505    640    505      640   \n",
      "7470    632    379     707     379    707    379    707    379      707   \n",
      "7471    475    527     475     527    475    527    475    527      475   \n",
      "\n",
      "      egtprpW  egfprpB  egfprpW  egerpB  egerpW  gsdpB  gsdpW  gseoB  gseoW  \\\n",
      "0         850      825      850     825     850    825    850    825    850   \n",
      "1         850      722      850     722     850    722    850    722    850   \n",
      "2         455      508      455     508     455    508    455    508    455   \n",
      "3         348      444      348     444     348    444    348    444    348   \n",
      "4         776      842      776     842     776    842    776    842    776   \n",
      "...       ...      ...      ...     ...     ...    ...    ...    ...    ...   \n",
      "7467      562      733      412     733     412    733    562    733    412   \n",
      "7468      379      621      379     621     379    621    379    621    379   \n",
      "7469      505      640      505     640     505    640    505    640    505   \n",
      "7470      379      707      379     707     379    707    379    707    379   \n",
      "7471      527      475      527     475     527    475    527    475    527   \n",
      "\n",
      "      gstprpB  gstprpW  gsfprpB  gsfprpW  gserpB  gserpW  \n",
      "0         825      850      825      850     825     850  \n",
      "1         722      850      722      850     722     850  \n",
      "2         508      455      508      455     508     455  \n",
      "3         444      348      444      348     444     348  \n",
      "4         842      776      842      776     842     776  \n",
      "...       ...      ...      ...      ...     ...     ...  \n",
      "7467      733      562      733      562     733     412  \n",
      "7468      621      379      621      379     621     379  \n",
      "7469      640      505      640      505     640     505  \n",
      "7470      707      379      707      379     707     379  \n",
      "7471      475      527      475      527     475     527  \n",
      "\n",
      "[7472 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scores Data Frames\n",
    "classifier_dfs = {}\n",
    "dfs_b = {}\n",
    "dfs_w = {}\n",
    "dfs_eg = {}\n",
    "dfs_gs = {}\n",
    "for f in folders:\n",
    "    path = f'{data_path}{f}/{f}_all_scores.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    df_black = df.filter(like='B')\n",
    "    df_white = df.filter(like='W')\n",
    "    df_eg = pd.concat([df.iloc[:,:4],df.filter(like='eg')],axis=1)\n",
    "    df_gs = pd.concat([df.iloc[:,:4],df.filter(like='gs')],axis=1)\n",
    "    \n",
    "    classifier_dfs[f] = df\n",
    "    dfs_b[f] = df_black\n",
    "    dfs_w[f] = df_white\n",
    "    dfs_eg[f] = df_eg\n",
    "    dfs_gs[f] = df_gs\n",
    "print(classifier_dfs['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if normal distributions:\n",
    "\n",
    "if p < 0.01 (or < 0.05) then the distribution is significantly different from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dt\n",
      "Check for norm Distributions done\n",
      "Classifier: gnb\n",
      "Check for norm Distributions done\n",
      "Classifier: lgr\n",
      "Check for norm Distributions done\n",
      "Classifier: gbt\n",
      "Check for norm Distributions done\n"
     ]
    }
   ],
   "source": [
    "for c,df in classifier_dfs.items():\n",
    "    print('Classifier:',c)\n",
    "    for col in df:\n",
    "        data=df[col].dropna(axis=0)\n",
    "        _,p = stats.kstest(data, \"norm\")\n",
    "        if p > 0.01:\n",
    "            print(col,',p:',p)\n",
    "    print('Check for norm Distributions done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann Whitney U test:\n",
    "\n",
    "“a two-sample rank test for the difference between two population medians . . . It assumes that the data are independent random samples from two populations that have the same shape.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_path = f'{data_path}mwu/'\n",
    "os.makedirs(mwu_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions EG vs. GS\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dt gnb lgr gbt\n",
      "Constraints               \n",
      "stB                       \n",
      "stW                       \n",
      "mitB                      \n",
      "mitW                      \n",
      "dpB          s   s   s   s\n",
      "dpW              s        \n",
      "eoB          s   s   s   s\n",
      "eoW          s   s   s   s\n",
      "tprpB                s    \n",
      "tprpW                     \n",
      "fprpB        s   s   s   s\n",
      "fprpW                s    \n",
      "erpB                      \n",
      "erpW             s   s    \n"
     ]
    }
   ],
   "source": [
    "p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "for (c1,df_eg),(c2,df_gs) in zip(dfs_eg.items(),dfs_gs.items()):\n",
    "    col_signi = []\n",
    "    col_vals = []\n",
    "    idx = []\n",
    "    \n",
    "    for col_eg,col_gs in zip(df_eg,df_gs):\n",
    "        \n",
    "        idx.append(col_eg[2:])\n",
    "        \n",
    "        data_eg=df_eg[col_eg].dropna(axis=0)\n",
    "        data_gs=df_gs[col_gs].dropna(axis=0)\n",
    "        \n",
    "        _,p = stats.mannwhitneyu(data_eg, data_gs)\n",
    "        \n",
    "        col_vals.append(p)\n",
    "        if p< 0.05:\n",
    "            col_signi.append('s')\n",
    "        else:\n",
    "            col_signi.append(' ')\n",
    "            \n",
    "    p_signi[c1] = col_signi\n",
    "    p_vals[c1] = col_vals\n",
    "    \n",
    "p_vals['Constraints'] = idx\n",
    "p_vals = p_vals.set_index('Constraints')\n",
    "p_signi['Constraints'] = idx\n",
    "p_signi = p_signi.set_index('Constraints')\n",
    "\n",
    "p_vals = p_vals.round(decimals=3)\n",
    "print(p_signi)\n",
    "    \n",
    "p_vals.to_csv(f'{mwu_path}p_eg_gs.csv')\n",
    "p_signi.to_csv(f'{mwu_path}significanz_eg_gs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions Each Model against each other\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_values_mwu_1model(dfs,model=''):\n",
    "    p_vals = pd.DataFrame(data={'Classifier': []})\n",
    "    p_signi = pd.DataFrame(data={'Classifier': []})\n",
    "    \n",
    "    for c1,df1 in dfs.items():\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data1 = df1[model].dropna(axis=0)\n",
    "        \n",
    "        for c2,df2 in dfs.items():\n",
    "            idx.append(c2)\n",
    "            \n",
    "            data2 =df2[model].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data1, data2)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c1] = col_signi\n",
    "        p_vals[c1] = col_vals\n",
    "        \n",
    "    p_vals['Classifier'] = idx\n",
    "    p_vals = p_vals.set_index('Classifier')\n",
    "    p_signi['Classifier'] = idx\n",
    "    p_signi = p_signi.set_index('Classifier')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_{model}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: testB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: testW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: unmitW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: egdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                     s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egtprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egtprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s    \n",
      "lgr             s        \n",
      "gbt                      \n",
      "\n",
      "C: egerpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                  s    \n",
      "gnb                 s    \n",
      "lgr         s   s       s\n",
      "gbt                 s    \n",
      "\n",
      "C: gsdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gseoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gseoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gstprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                  s    \n",
      "gnb                 s    \n",
      "lgr         s   s       s\n",
      "gbt                 s    \n",
      "\n",
      "C: gstprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s   s    \n",
      "gnb         s           s\n",
      "lgr         s           s\n",
      "gbt             s   s    \n",
      "\n",
      "C: gsfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s   s    \n",
      "gnb         s           s\n",
      "lgr         s           s\n",
      "gbt             s   s    \n",
      "\n",
      "C: gserpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gserpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s   s    \n",
      "gnb         s           s\n",
      "lgr         s           s\n",
      "gbt             s   s    \n"
     ]
    }
   ],
   "source": [
    "for col in classifier_dfs['dt']:\n",
    "    print('\\nC:',col)\n",
    "    p_values_mwu_1model(classifier_dfs,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions unmitigated v Mitigated for each race\n",
    "\n",
    "if p < 0.001 (or < 0.0005) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_race_mwu(dfs, b_or_w = 'B'):\n",
    "    p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "    p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "    for c,df in dfs.items():\n",
    "        \n",
    "        c = f'{c}{b_or_w}'\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data_unmiti = df[f'unmit{b_or_w}'].dropna(axis=0)\n",
    "        \n",
    "        for col in df:\n",
    "            \n",
    "            idx.append(col[:-1])\n",
    "            \n",
    "            data_miti=df[col].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data_unmiti, data_miti)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c] = col_signi\n",
    "        p_vals[c] = col_vals\n",
    "        \n",
    "    p_vals['Constraints'] = idx\n",
    "    p_vals = p_vals.set_index('Constraints')\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_signi['Constraints'] = idx\n",
    "    p_signi = p_signi.set_index('Constraints')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_un_vs_miti_{b_or_w}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_un_vs_miti_{b_or_w}.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:\n",
      "            dtB gnbB lgrB gbtB\n",
      "Constraints                   \n",
      "test          s    s    s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo          s    s    s    s\n",
      "egtprp        s    s    s    s\n",
      "egfprp             s    s     \n",
      "egerp                         \n",
      "gsdp          s    s    s    s\n",
      "gseo                          \n",
      "gstprp        s    s    s    s\n",
      "gsfprp        s    s         s\n",
      "gserp                         \n",
      "\n",
      "White:\n",
      "            dtW gnbW lgrW gbtW\n",
      "Constraints                   \n",
      "test          s         s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo          s    s    s    s\n",
      "egtprp        s    s    s    s\n",
      "egfprp        s    s    s    s\n",
      "egerp                         \n",
      "gsdp          s    s    s    s\n",
      "gseo                          \n",
      "gstprp        s    s    s    s\n",
      "gsfprp        s    s         s\n",
      "gserp              s    s     \n"
     ]
    }
   ],
   "source": [
    "print('Black:')\n",
    "p_race_mwu(dfs_b,'B')\n",
    "\n",
    "print('\\nWhite:')\n",
    "p_race_mwu(dfs_w,'W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairness Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Acc  Fairness Metric Value Difference to Unmitigated\n",
      "Run                                                                         \n",
      "dt Unmitigated        81.61                                              NaN\n",
      "dt EG DP Mitigated    75.02                                             0.98\n",
      "dt EG EO Mitigated    79.45                                           -17.09\n",
      "dt EG TPRP Mitigated  79.78                                           -21.72\n",
      "dt EG FPRP Mitigated  82.71                                           -19.61\n",
      "dt EG ERP Mitigated   80.13                                            -0.29\n",
      "dt GS DP Mitigated    67.66                                            25.15\n",
      "dt GS EO Mitigated    81.61                                             0.00\n",
      "dt GS TPRP Mitigated  77.26                                           -17.49\n",
      "dt GS FPRP Mitigated  81.61                                             0.00\n",
      "dt GS ERP Mitigated   81.61                                             0.00\n",
      "                        Acc  Fairness Metric Value Difference to Unmitigated\n",
      "Run                                                                         \n",
      "dt Unmitigated        83.06                                              NaN\n",
      "dt EG DP Mitigated    76.95                                             2.90\n",
      "dt EG EO Mitigated    82.37                                           -11.33\n",
      "dt EG TPRP Mitigated  80.50                                           -11.22\n",
      "dt EG FPRP Mitigated  82.44                                           -13.45\n",
      "dt EG ERP Mitigated   81.12                                             3.88\n",
      "dt GS DP Mitigated    74.44                                             9.49\n",
      "dt GS EO Mitigated    83.06                                             0.00\n",
      "dt GS TPRP Mitigated  80.58                                           -11.11\n",
      "dt GS FPRP Mitigated  83.06                                             0.00\n",
      "dt GS ERP Mitigated   83.06                                             0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_48052\\963955507.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Fairness Metric Value Difference to Unmitigated'] = df.iloc[:,1]\n",
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_48052\\963955507.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Fairness Metric Value Difference to Unmitigated'] = df.iloc[:,1]\n"
     ]
    }
   ],
   "source": [
    "# Absolute numbers\n",
    "dfs = {} # list for pandas dfs\n",
    "datasets = ['00', '0b', '0i', 'b0','bb','bi','i0','ib','ii']\n",
    "datasets = ['00', '0b']\n",
    "folders = ['dt']\n",
    "#pd.set_option('display.max_columns', None)\n",
    "for _,f in enumerate(folders):\n",
    "    for _,ds in enumerate(datasets):\n",
    "        path = f'../results/synthetic_balTestSet/{ds}/{f}/{f}_overall_results.csv'\n",
    "        df = pd.read_csv(path)\n",
    "        df = pd.concat([df.iloc[:,:2], df.iloc[:,13:]],axis= 1)\n",
    "        df = df.set_index('Run')\n",
    "        df2 = df.iloc[:,:1]\n",
    "        df2['Fairness Metric Value Difference to Unmitigated'] = df.iloc[:,1]\n",
    "        df2.iloc[0,1] = None\n",
    "\n",
    "        for i in range(1,6):\n",
    "            df2.iloc[i,1] = df.iloc[i,i]-df.iloc[0,i]\n",
    "            df2.iloc[i+5,1] = df.iloc[i+5,i]-df.iloc[0,i]\n",
    "        print(df2)  \n",
    "        dfs[f] = df2\n",
    "        #print('\\nClassifier: ',f,'\\n DataFrame: \\n',df)\n",
    "        #df.to_csv(f'{data_path}{f}/{f}_type_absolute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats.pearsonr(data_unmiti, data_miti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "for c1,df1 in classifier_dfs.items():\n",
    "   \n",
    "    idx = []\n",
    "    \n",
    "    for col1 in df1:\n",
    "        data1=df1[col1].dropna(axis=0)\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        for c2,df2 in classifier_dfs.items():\n",
    "            \n",
    "            for col2 in df2:\n",
    "                data2=df2[col2].dropna(axis=0)\n",
    "                idx.append(f'{c2}{col2}')\n",
    "                \n",
    "                _,p = stats.mannwhitneyu(data1, data2)\n",
    "\n",
    "                col_vals.append(p)\n",
    "                if p< 0.05:\n",
    "                    col_signi.append('s')\n",
    "                else:\n",
    "                    col_signi.append(' ')\n",
    "        print(f'{c1}{col1}')\n",
    "        p_signi[f'{c1}{col1}'] = col_signi\n",
    "        p_vals[f'{c1}{col1}'] = col_vals\n",
    "idx = idx[:96]\n",
    "p_vals['Constraints'] = idx\n",
    "p_vals = p_vals.set_index('Constraints')\n",
    "p_signi['Constraints'] = idx\n",
    "p_signi = p_signi.set_index('Constraints')\n",
    "\n",
    "p_vals = p_vals.round(decimals=3)\n",
    "    \n",
    "p_vals.to_csv(f'{mwu_path}p_all.csv')\n",
    "p_signi.to_csv(f'{mwu_path}significanz_all.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
