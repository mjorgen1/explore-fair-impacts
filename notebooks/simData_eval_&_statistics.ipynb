{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/results/synthetic_test1/bb_smallTS/'\n",
    "folders= ['dt','gnb','lgr','gbt']\n",
    "#folders= ['dt','gnb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_csvs(data_path= 'data/results/',b_or_w = 'Black', folders= ['dt','gnb','lgr','gbt']):\n",
    "\n",
    "    col_names_eg = []\n",
    "    col_names_gs = []\n",
    "\n",
    "    for i,f in enumerate(folders):\n",
    "        if b_or_w == 'Black':\n",
    "            path = f'{data_path}{f}/{f}_black_results.csv'\n",
    "        else:\n",
    "            path = f'{data_path}{f}/{f}_white_results.csv'\n",
    "\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        col_names_eg.append(f'EG+{f.upper()}')\n",
    "        col_names_gs.append(f'GS+{f.upper()}')\n",
    "\n",
    "        if i == 0:\n",
    "            joined_df = df.iloc[:,-1]\n",
    "        else:\n",
    "            joined_df = pd.concat([joined_df, df.iloc[:,-1]], axis=1)\n",
    "\n",
    "    joined_df.set_axis(folders, axis=1)\n",
    "\n",
    "\n",
    "    # split dataframe after the two reduction algorithms\n",
    "    df_eg = joined_df.iloc[:6,:]\n",
    "    df_gs = pd.concat([joined_df.iloc[0:1,:],joined_df.iloc[6:,:]])\n",
    "\n",
    "    # set new index\n",
    "    df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_eg.set_index('Constraint',inplace=True)\n",
    "    df_gs['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_gs.set_index('Constraint',inplace=True)\n",
    "    df_eg.columns = col_names_eg\n",
    "    df_gs.columns = col_names_gs\n",
    "\n",
    "    df_final = pd.concat([df_eg, df_gs], axis=1)\n",
    "    print('Group: ',b_or_w,'\\n DataFrame: \\n',df_final)\n",
    "    print('A')\n",
    "    df_final.to_csv(f'{data_path}/{b_or_w}_DI.csv')\n",
    "    print('B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  Black \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated  16.80   19.23   16.80   16.78  16.80   19.23   16.80   16.78\n",
      "DP            3.33    1.25    2.38    3.38  13.58   14.88    5.95   12.80\n",
      "EO           14.88   12.30   13.83   14.88  16.80   19.23   16.80   16.78\n",
      "EOO          14.88   11.35   12.10   14.88  14.88   16.65   12.13   14.88\n",
      "FPER         15.38   13.20   15.20   15.30  16.80   19.23   16.80   16.78\n",
      "ERP          16.80   19.33   16.83   16.80  16.80   19.10   16.80   16.80\n",
      "A\n",
      "B\n",
      "Group:  White \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated   8.06    2.08    7.36    7.68   8.06    2.08    7.36    7.68\n",
      "DP           17.16   15.98   16.56   17.18  13.86    8.56   15.03   14.23\n",
      "EO           12.85   10.24   11.71   13.40   8.06    2.08    7.36    7.68\n",
      "EOO          15.21   12.20   12.26   15.58  13.51    5.16   12.93   13.21\n",
      "FPER         13.51   11.26   12.58   12.93   8.06    2.08    7.36    7.68\n",
      "ERP           5.74    1.10    6.11    5.00   8.06   -7.72   -9.62    7.36\n",
      "A\n",
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_10244\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_10244\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n"
     ]
    }
   ],
   "source": [
    "impact_csvs(data_path,'Black', folders= ['dt','gnb','lgr','gbt'])\n",
    "impact_csvs(data_path,'White', folders= ['dt','gnb','lgr','gbt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FP/TP/TN/FN Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.035  0.076  0.061  0.060   0.084   0.049    0.069    0.042   \n",
      "FP        0.204  0.079  0.114  0.117   0.090   0.174    0.107    0.121   \n",
      "TN        0.296  0.421  0.386  0.383   0.410   0.326    0.393    0.379   \n",
      "TP        0.465  0.424  0.439  0.440   0.416   0.451    0.431    0.458   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.061    0.058  0.060  0.046  0.084  0.026   0.084   0.026   \n",
      "FP          0.114    0.102  0.123  0.116  0.090  0.165   0.090   0.165   \n",
      "TN          0.386    0.398  0.377  0.384  0.410  0.335   0.410   0.335   \n",
      "TP          0.439    0.442  0.440  0.454  0.416  0.474   0.416   0.474   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.084    0.026    0.061    0.042    0.0    0.0   0.084   0.026  \n",
      "FP          0.090    0.165    0.114    0.121    0.0    0.0   0.090   0.165  \n",
      "TN          0.410    0.335    0.386    0.379    0.5    0.5   0.410   0.335  \n",
      "TP          0.416    0.474    0.439    0.458    0.5    0.5   0.416   0.474  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.028  0.065  0.059  0.058   0.123   0.051    0.063    0.036   \n",
      "FP        0.222  0.093  0.133  0.136   0.054   0.200    0.124    0.139   \n",
      "TN        0.278  0.407  0.367  0.364   0.446   0.300    0.376    0.361   \n",
      "TP        0.472  0.435  0.441  0.442   0.377   0.449    0.437    0.464   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.056    0.052  0.061  0.028  0.134  0.013   0.125   0.007   \n",
      "FP          0.142    0.125  0.114  0.161  0.049  0.212   0.054   0.280   \n",
      "TN          0.358    0.375  0.386  0.339  0.451  0.288   0.446   0.220   \n",
      "TP          0.444    0.448  0.439  0.472  0.366  0.487   0.375   0.493   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.134    0.013    0.081    0.018    0.0    0.0   0.134   0.013  \n",
      "FP          0.049    0.212    0.092    0.189    0.0    0.0   0.049   0.212  \n",
      "TN          0.451    0.288    0.408    0.311    0.5    0.5   0.451   0.288  \n",
      "TP          0.366    0.487    0.419    0.482    0.5    0.5   0.366   0.487  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.031  0.072  0.059  0.058   0.084   0.059    0.063    0.040   \n",
      "FP        0.212  0.086  0.122  0.125   0.090   0.163    0.111    0.128   \n",
      "TN        0.288  0.414  0.378  0.375   0.410   0.337    0.389    0.372   \n",
      "TP        0.469  0.428  0.441  0.442   0.416   0.441    0.437    0.460   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.056    0.054  0.040  0.057  0.084  0.024   0.084   0.006   \n",
      "FP          0.135    0.123  0.184  0.103  0.090  0.171   0.090   0.293   \n",
      "TN          0.365    0.377  0.316  0.397  0.410  0.329   0.410   0.207   \n",
      "TP          0.444    0.446  0.460  0.443  0.416  0.476   0.416   0.494   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.084    0.024    0.057    0.041    0.0    0.0   0.084   0.024  \n",
      "FP          0.090    0.171    0.135    0.125    0.0    0.0   0.090   0.171  \n",
      "TN          0.410    0.329    0.365    0.375    0.5    0.5   0.410   0.329  \n",
      "TP          0.416    0.476    0.443    0.459    0.5    0.5   0.416   0.476  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.035  0.077  0.061  0.056   0.084   0.045    0.066    0.041   \n",
      "FP        0.204  0.079  0.114  0.116   0.090   0.181    0.109    0.125   \n",
      "TN        0.296  0.421  0.386  0.384   0.410   0.319    0.391    0.375   \n",
      "TP        0.465  0.423  0.439  0.444   0.416   0.455    0.434    0.459   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.061    0.055  0.059  0.049  0.090  0.025   0.084   0.024   \n",
      "FP          0.114    0.100  0.129  0.113  0.087  0.168   0.090   0.171   \n",
      "TN          0.386    0.400  0.371  0.387  0.413  0.332   0.410   0.329   \n",
      "TP          0.439    0.445  0.441  0.451  0.410  0.475   0.416   0.476   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.090    0.025    0.061    0.043    0.0    0.0   0.090   0.025  \n",
      "FP          0.087    0.168    0.114    0.122    0.0    0.0   0.087   0.168  \n",
      "TN          0.413    0.332    0.386    0.378    0.5    0.5   0.413   0.332  \n",
      "TP          0.410    0.475    0.439    0.457    0.5    0.5   0.410   0.475  \n"
     ]
    }
   ],
   "source": [
    "# Ratios\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts(normalize=True)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Ratio'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Ratio']\n",
    "    df = df.fillna(0)\n",
    "    df = df.round(decimals = 3)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         104.0   229.0   184.0   180.0   251.0   146.0    206.0    125.0   \n",
      "FP         613.0   238.0   342.0   351.0   270.0   523.0    321.0    363.0   \n",
      "TN         887.0  1262.0  1158.0  1149.0  1230.0   977.0   1179.0   1137.0   \n",
      "TP        1396.0  1271.0  1316.0  1320.0  1249.0  1354.0   1294.0   1375.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          184.0    173.0   180.0   139.0   251.0    79.0   251.0    79.0   \n",
      "FP          342.0    305.0   370.0   349.0   270.0   495.0   270.0   495.0   \n",
      "TN         1158.0   1195.0  1130.0  1151.0  1230.0  1005.0  1230.0  1005.0   \n",
      "TP         1316.0   1327.0  1320.0  1361.0  1249.0  1421.0  1249.0  1421.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          251.0     79.0    184.0    125.0     0.0     0.0   251.0    79.0  \n",
      "FP          270.0    495.0    342.0    363.0     0.0     0.0   270.0   495.0  \n",
      "TN         1230.0   1005.0   1158.0   1137.0  1500.0  1500.0  1230.0  1005.0  \n",
      "TP         1249.0   1421.0   1316.0   1375.0  1500.0  1500.0  1249.0  1421.0  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN          83.0   196.0   177.0   173.0   368.0   153.0    189.0    107.0   \n",
      "FP         665.0   278.0   398.0   407.0   161.0   601.0    373.0    417.0   \n",
      "TN         835.0  1222.0  1102.0  1093.0  1339.0   899.0   1127.0   1083.0   \n",
      "TP        1417.0  1304.0  1323.0  1327.0  1132.0  1347.0   1311.0   1393.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          168.0    156.0   184.0    85.0   402.0    38.0   375.0    22.0   \n",
      "FP          425.0    374.0   342.0   482.0   146.0   635.0   162.0   839.0   \n",
      "TN         1075.0   1126.0  1158.0  1018.0  1354.0   865.0  1338.0   661.0   \n",
      "TP         1332.0   1344.0  1316.0  1415.0  1098.0  1462.0  1125.0  1478.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          402.0     38.0    243.0     53.0     0.0     0.0   402.0    38.0  \n",
      "FP          146.0    635.0    277.0    566.0     0.0     0.0   146.0   635.0  \n",
      "TN         1354.0    865.0   1223.0    934.0  1500.0  1500.0  1354.0   865.0  \n",
      "TP         1098.0   1462.0   1257.0   1447.0  1500.0  1500.0  1098.0  1462.0  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN          94.0   215.0   178.0   175.0   252.0   178.0    189.0    120.0   \n",
      "FP         637.0   257.0   366.0   374.0   269.0   488.0    333.0    384.0   \n",
      "TN         863.0  1243.0  1134.0  1126.0  1231.0  1012.0   1167.0   1116.0   \n",
      "TP        1406.0  1285.0  1322.0  1325.0  1248.0  1322.0   1311.0   1380.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          169.0    163.0   121.0   172.0   251.0    71.0   251.0    18.0   \n",
      "FP          405.0    369.0   552.0   309.0   270.0   513.0   270.0   879.0   \n",
      "TN         1095.0   1131.0   948.0  1191.0  1230.0   987.0  1230.0   621.0   \n",
      "TP         1331.0   1337.0  1379.0  1328.0  1249.0  1429.0  1249.0  1482.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          251.0     71.0    170.0    122.0     0.0     0.0   251.0    71.0  \n",
      "FP          270.0    513.0    404.0    376.0     0.0     0.0   270.0   513.0  \n",
      "TN         1230.0    987.0   1096.0   1124.0  1500.0  1500.0  1230.0   987.0  \n",
      "TP         1249.0   1429.0   1330.0   1378.0  1500.0  1500.0  1249.0  1429.0  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         104.0   230.0   184.0   169.0   251.0   136.0    197.0    122.0   \n",
      "FP         612.0   237.0   342.0   349.0   270.0   543.0    327.0    376.0   \n",
      "TN         888.0  1263.0  1158.0  1151.0  1230.0   957.0   1173.0   1124.0   \n",
      "TP        1396.0  1270.0  1316.0  1331.0  1249.0  1364.0   1303.0   1378.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          184.0    166.0   177.0   146.0   270.0    76.0   251.0    71.0   \n",
      "FP          342.0    301.0   387.0   338.0   261.0   504.0   270.0   513.0   \n",
      "TN         1158.0   1199.0  1113.0  1162.0  1239.0   996.0  1230.0   987.0   \n",
      "TP         1316.0   1334.0  1323.0  1354.0  1230.0  1424.0  1249.0  1429.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          270.0     76.0    184.0    129.0     0.0     0.0   270.0    76.0  \n",
      "FP          261.0    504.0    342.0    367.0     0.0     0.0   261.0   504.0  \n",
      "TN         1239.0    996.0   1158.0   1133.0  1500.0  1500.0  1239.0   996.0  \n",
      "TP         1230.0   1424.0   1316.0   1371.0  1500.0  1500.0  1230.0  1424.0  \n"
     ]
    }
   ],
   "source": [
    "# Absolute numbers\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts()\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Number'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Number']\n",
    "    df = df.fillna(0)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_absolute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractig Scores from csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      testB  testW  unmitB  unmitW  egdpB  egdpW  egeoB  egeoW  egtprpB  \\\n",
      "0       605    622     680     697    680    697    680    697      680   \n",
      "1       543    555     393     405    393    555    393    555      393   \n",
      "2       568    502     643     502    643    502    643    502      643   \n",
      "3       632    728     707     803    707    803    707    803      707   \n",
      "4       622    390     472     390    472    390    472    390      472   \n",
      "...     ...    ...     ...     ...    ...    ...    ...    ...      ...   \n",
      "2995    430    832     430     682    430    682    430    682      430   \n",
      "2996    406    570     406     420    406    570    406    570      406   \n",
      "2997    524    502     524     502    374    502    374    502      374   \n",
      "2998    411    738     411     588    411    588    411    588      411   \n",
      "2999    396    439     396     439    396    439    396    439      396   \n",
      "\n",
      "      egtprpW  egfprpB  egfprpW  egerpB  egerpW  gsdpB  gsdpW  gseoB  gseoW  \\\n",
      "0         697      680      697     680     697    680    697    680    697   \n",
      "1         555      393      555     393     405    393    555    393    405   \n",
      "2         502      643      502     643     502    643    502    643    502   \n",
      "3         803      707      803     707     803    707    803    707    803   \n",
      "4         390      472      390     472     390    472    390    472    390   \n",
      "...       ...      ...      ...     ...     ...    ...    ...    ...    ...   \n",
      "2995      682      430      682     430     832    430    682    430    682   \n",
      "2996      570      406      420     406     420    406    570    406    420   \n",
      "2997      502      374      502     524     502    374    502    524    502   \n",
      "2998      588      411      588     411     738    411    588    411    588   \n",
      "2999      439      396      439     396     439    396    439    396    439   \n",
      "\n",
      "      gstprpB  gstprpW  gsfprpB  gsfprpW  gserpB  gserpW  \n",
      "0         680      697      680      697     680     697  \n",
      "1         393      555      393      405     393     405  \n",
      "2         643      502      643      502     643     502  \n",
      "3         707      803      707      803     707     803  \n",
      "4         472      390      472      390     472     390  \n",
      "...       ...      ...      ...      ...     ...     ...  \n",
      "2995      430      682      430      682     430     682  \n",
      "2996      406      420      406      420     406     420  \n",
      "2997      374      502      524      502     524     502  \n",
      "2998      411      588      411      588     411     588  \n",
      "2999      396      439      396      439     396     439  \n",
      "\n",
      "[3000 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scores Data Frames\n",
    "classifier_dfs = {}\n",
    "dfs_b = {}\n",
    "dfs_w = {}\n",
    "dfs_eg = {}\n",
    "dfs_gs = {}\n",
    "for f in folders:\n",
    "    path = f'{data_path}{f}/{f}_all_scores.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    df_black = df.filter(like='B')\n",
    "    df_white = df.filter(like='W')\n",
    "    df_eg = pd.concat([df.iloc[:,:4],df.filter(like='eg')],axis=1)\n",
    "    df_gs = pd.concat([df.iloc[:,:4],df.filter(like='gs')],axis=1)\n",
    "    \n",
    "    classifier_dfs[f] = df\n",
    "    dfs_b[f] = df_black\n",
    "    dfs_w[f] = df_white\n",
    "    dfs_eg[f] = df_eg\n",
    "    dfs_gs[f] = df_gs\n",
    "print(classifier_dfs['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if normal distributions:\n",
    "\n",
    "if p < 0.01 (or < 0.05) then the distribution is significantly different from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dt\n",
      "Check for norm Distributions done\n",
      "Classifier: gnb\n",
      "Check for norm Distributions done\n",
      "Classifier: lgr\n",
      "Check for norm Distributions done\n",
      "Classifier: gbt\n",
      "Check for norm Distributions done\n"
     ]
    }
   ],
   "source": [
    "for c,df in classifier_dfs.items():\n",
    "    print('Classifier:',c)\n",
    "    for col in df:\n",
    "        data=df[col].dropna(axis=0)\n",
    "        _,p = stats.kstest(data, \"norm\")\n",
    "        if p > 0.01:\n",
    "            print(col,',p:',p)\n",
    "    print('Check for norm Distributions done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann Whitney U test:\n",
    "\n",
    "“a two-sample rank test for the difference between two population medians . . . It assumes that the data are independent random samples from two populations that have the same shape.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_path = f'{data_path}mwu/'\n",
    "os.makedirs(mwu_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions EG vs. GS\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dt gnb lgr gbt\n",
      "Constraints               \n",
      "stB                       \n",
      "stW                       \n",
      "mitB                      \n",
      "mitW                      \n",
      "dpB          s   s       s\n",
      "dpW              s        \n",
      "eoB              s        \n",
      "eoW              s       s\n",
      "tprpB            s        \n",
      "tprpW            s        \n",
      "fprpB            s        \n",
      "fprpW        s   s   s   s\n",
      "erpB                      \n",
      "erpW             s   s    \n"
     ]
    }
   ],
   "source": [
    "p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "for (c1,df_eg),(c2,df_gs) in zip(dfs_eg.items(),dfs_gs.items()):\n",
    "    col_signi = []\n",
    "    col_vals = []\n",
    "    idx = []\n",
    "    \n",
    "    for col_eg,col_gs in zip(df_eg,df_gs):\n",
    "        \n",
    "        idx.append(col_eg[2:])\n",
    "        \n",
    "        data_eg=df_eg[col_eg].dropna(axis=0)\n",
    "        data_gs=df_gs[col_gs].dropna(axis=0)\n",
    "        \n",
    "        _,p = stats.mannwhitneyu(data_eg, data_gs)\n",
    "        \n",
    "        col_vals.append(p)\n",
    "        if p< 0.05:\n",
    "            col_signi.append('s')\n",
    "        else:\n",
    "            col_signi.append(' ')\n",
    "            \n",
    "    p_signi[c1] = col_signi\n",
    "    p_vals[c1] = col_vals\n",
    "    \n",
    "p_vals['Constraints'] = idx\n",
    "p_vals = p_vals.set_index('Constraints')\n",
    "p_signi['Constraints'] = idx\n",
    "p_signi = p_signi.set_index('Constraints')\n",
    "\n",
    "p_vals = p_vals.round(decimals=3)\n",
    "print(p_signi)\n",
    "    \n",
    "p_vals.to_csv(f'{mwu_path}p_eg_gs.csv')\n",
    "p_signi.to_csv(f'{mwu_path}significanz_eg_gs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions Each Model against each other\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_values_mwu_1model(dfs,model=''):\n",
    "    p_vals = pd.DataFrame(data={'Classifier': []})\n",
    "    p_signi = pd.DataFrame(data={'Classifier': []})\n",
    "    \n",
    "    for c1,df1 in dfs.items():\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data1 = df1[model].dropna(axis=0)\n",
    "        \n",
    "        for c2,df2 in dfs.items():\n",
    "            idx.append(c2)\n",
    "            \n",
    "            data2 =df2[model].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data1, data2)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c1] = col_signi\n",
    "        p_vals[c1] = col_vals\n",
    "        \n",
    "    p_vals['Classifier'] = idx\n",
    "    p_vals = p_vals.set_index('Classifier')\n",
    "    p_signi['Classifier'] = idx\n",
    "    p_signi = p_signi.set_index('Classifier')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_{model}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: testB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: testW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: egdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egtprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egtprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gsdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                  s    \n",
      "gnb                 s    \n",
      "lgr         s   s       s\n",
      "gbt                 s    \n",
      "\n",
      "C: gsdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gseoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gseoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gstprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                 s    \n",
      "lgr             s        \n",
      "gbt                      \n",
      "\n",
      "C: gstprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gsfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gserpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gserpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s   s    \n",
      "gnb         s           s\n",
      "lgr         s           s\n",
      "gbt             s   s    \n"
     ]
    }
   ],
   "source": [
    "for col in classifier_dfs['dt']:\n",
    "    print('\\nC:',col)\n",
    "    p_values_mwu_1model(classifier_dfs,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions unmitigated v Mitigated for each race\n",
    "\n",
    "if p < 0.001 (or < 0.0005) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_race_mwu(dfs, b_or_w = 'B'):\n",
    "    p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "    p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "    for c,df in dfs.items():\n",
    "        \n",
    "        c = f'{c}{b_or_w}'\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data_unmiti = df[f'unmit{b_or_w}'].dropna(axis=0)\n",
    "        \n",
    "        for col in df:\n",
    "            \n",
    "            idx.append(col[:-1])\n",
    "            \n",
    "            data_miti=df[col].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data_unmiti, data_miti)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c] = col_signi\n",
    "        p_vals[c] = col_vals\n",
    "        \n",
    "    p_vals['Constraints'] = idx\n",
    "    p_vals = p_vals.set_index('Constraints')\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_signi['Constraints'] = idx\n",
    "    p_signi = p_signi.set_index('Constraints')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_un_vs_miti_{b_or_w}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_un_vs_miti_{b_or_w}.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:\n",
      "            dtB gnbB lgrB gbtB\n",
      "Constraints                   \n",
      "test          s    s    s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo               s          \n",
      "egtprp             s    s     \n",
      "egfprp             s          \n",
      "egerp                         \n",
      "gsdp               s    s    s\n",
      "gseo                          \n",
      "gstprp             s    s     \n",
      "gsfprp                        \n",
      "gserp                         \n",
      "\n",
      "White:\n",
      "            dtW gnbW lgrW gbtW\n",
      "Constraints                   \n",
      "test          s         s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo               s         s\n",
      "egtprp        s    s         s\n",
      "egfprp        s    s    s    s\n",
      "egerp                         \n",
      "gsdp          s    s    s    s\n",
      "gseo                          \n",
      "gstprp        s         s    s\n",
      "gsfprp                        \n",
      "gserp              s    s     \n"
     ]
    }
   ],
   "source": [
    "print('Black:')\n",
    "p_race_mwu(dfs_b,'B')\n",
    "\n",
    "print('\\nWhite:')\n",
    "p_race_mwu(dfs_w,'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_unmiti' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stats\u001b[38;5;241m.\u001b[39mpearsonr(\u001b[43mdata_unmiti\u001b[49m, data_miti)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_unmiti' is not defined"
     ]
    }
   ],
   "source": [
    "stats.pearsonr(data_unmiti, data_miti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
