{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/results/testset_balanced_200_1/'\n",
    "folders= ['dt','gnb','lgr','gbt']\n",
    "#folders= ['dt','gnb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_csvs(data_path= 'data/results/',b_or_w = 'Black', folders= ['dt','gnb','lgr','gbt']):\n",
    "\n",
    "    col_names_eg = []\n",
    "    col_names_gs = []\n",
    "\n",
    "    for i,f in enumerate(folders):\n",
    "        if b_or_w == 'Black':\n",
    "            path = f'{data_path}{f}/{f}_black_results.csv'\n",
    "        else:\n",
    "            path = f'{data_path}{f}/{f}_white_results.csv'\n",
    "\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        col_names_eg.append(f'EG+{f.upper()}')\n",
    "        col_names_gs.append(f'GS+{f.upper()}')\n",
    "\n",
    "        if i == 0:\n",
    "            joined_df = df.iloc[:,-1]\n",
    "        else:\n",
    "            joined_df = pd.concat([joined_df, df.iloc[:,-1]], axis=1)\n",
    "\n",
    "    joined_df.set_axis(folders, axis=1)\n",
    "\n",
    "\n",
    "    # split dataframe after the two reduction algorithms\n",
    "    df_eg = joined_df.iloc[:6,:]\n",
    "    df_gs = pd.concat([joined_df.iloc[0:1,:],joined_df.iloc[6:,:]])\n",
    "\n",
    "    # set new index\n",
    "    df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_eg.set_index('Constraint',inplace=True)\n",
    "    df_gs['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_gs.set_index('Constraint',inplace=True)\n",
    "    df_eg.columns = col_names_eg\n",
    "    df_gs.columns = col_names_gs\n",
    "\n",
    "    df_final = pd.concat([df_eg, df_gs], axis=1)\n",
    "    print('Group: ',b_or_w,'\\n DataFrame: \\n',df_final)\n",
    "    print('A')\n",
    "    df_final.to_csv(f'{data_path}/{b_or_w}_DI.csv')\n",
    "    print('B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  Black \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated  19.05   17.87   19.19   19.16  19.05   17.87   19.19   19.16\n",
      "DP            2.99    1.92    3.00    3.72  17.16   19.07   16.05   17.16\n",
      "EO           16.89   15.54   14.94   17.16  19.05   17.87   19.19   19.16\n",
      "EOO          16.76   16.08   15.58   17.05  16.76   17.67   15.58   17.16\n",
      "FPER         17.44   16.37   16.78   17.35  19.05   17.87   19.19   19.16\n",
      "ERP          19.05   17.92   19.20   19.16  19.05   18.15   19.19   19.16\n",
      "A\n",
      "B\n",
      "Group:  White \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated   9.75    3.57   10.02   10.42   9.75    3.57   10.02   10.42\n",
      "DP           18.29   18.66   18.60   18.64  16.33   11.42   16.52   16.64\n",
      "EO           16.58   15.72   14.59   16.75   9.75    3.57   10.02   10.42\n",
      "EOO          17.64   17.03   17.27   17.65  17.03   12.14   17.26   17.74\n",
      "FPER         16.64   16.25   16.58   16.62   9.75    3.57   10.02   10.42\n",
      "ERP           8.46    3.49    9.65    9.04   9.75  -11.11   10.02   11.42\n",
      "A\n",
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_6100\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_6100\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n"
     ]
    }
   ],
   "source": [
    "impact_csvs(data_path,'Black', folders= ['dt','gnb','lgr','gbt'])\n",
    "impact_csvs(data_path,'White', folders= ['dt','gnb','lgr','gbt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FP/TP/TN/FN Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.039  0.124  0.080  0.075   0.134   0.035    0.086    0.059   \n",
      "FP        0.204  0.046  0.091  0.082   0.049   0.159    0.084    0.090   \n",
      "TN        0.296  0.454  0.409  0.418   0.451   0.341    0.416    0.410   \n",
      "TP        0.461  0.376  0.420  0.425   0.366   0.465    0.414    0.441   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.080    0.076  0.082  0.057  0.134  0.025   0.134   0.025   \n",
      "FP          0.092    0.074  0.088  0.093  0.049  0.153   0.049   0.153   \n",
      "TN          0.408    0.426  0.412  0.407  0.451  0.347   0.451   0.347   \n",
      "TP          0.420    0.424  0.418  0.443  0.366  0.475   0.366   0.475   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.134    0.025    0.080    0.066    0.0    0.0   0.134   0.025  \n",
      "FP          0.049    0.153    0.092    0.084    0.0    0.0   0.049   0.153  \n",
      "TN          0.451    0.347    0.408    0.416    0.5    0.5   0.451   0.347  \n",
      "TP          0.366    0.475    0.420    0.434    0.5    0.5   0.366   0.475  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.035  0.115  0.077  0.072   0.191   0.033    0.084    0.055   \n",
      "FP        0.213  0.048  0.101  0.089   0.028   0.191    0.093    0.095   \n",
      "TN        0.287  0.452  0.399  0.411   0.472   0.309    0.407    0.405   \n",
      "TP        0.465  0.385  0.423  0.428   0.309   0.467    0.416    0.445   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.077    0.071  0.112  0.030  0.193  0.016   0.186   0.007   \n",
      "FP          0.098    0.081  0.060  0.139  0.028  0.198   0.030   0.301   \n",
      "TN          0.402    0.419  0.440  0.361  0.472  0.302   0.470   0.199   \n",
      "TP          0.423    0.429  0.388  0.470  0.307  0.484   0.314   0.493   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.193    0.016    0.089    0.032    0.0    0.0   0.193   0.016  \n",
      "FP          0.028    0.198    0.081    0.133    0.0    0.0   0.028   0.198  \n",
      "TN          0.472    0.302    0.419    0.367    0.5    0.5   0.472   0.302  \n",
      "TP          0.307    0.484    0.411    0.468    0.5    0.5   0.307   0.484  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.039  0.123  0.084  0.077   0.139   0.041    0.086    0.057   \n",
      "FP        0.204  0.045  0.104  0.094   0.046   0.145    0.089    0.091   \n",
      "TN        0.296  0.455  0.396  0.406   0.454   0.355    0.411    0.409   \n",
      "TP        0.461  0.377  0.416  0.423   0.361   0.459    0.414    0.443   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.071    0.068  0.075  0.057  0.139  0.025   0.139   0.025   \n",
      "FP          0.104    0.081  0.099  0.091  0.046  0.151   0.046   0.151   \n",
      "TN          0.396    0.419  0.401  0.409  0.454  0.349   0.454   0.349   \n",
      "TP          0.429    0.432  0.425  0.443  0.361  0.475   0.361   0.475   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.139    0.025    0.071    0.068    0.0    0.0   0.139   0.025  \n",
      "FP          0.046    0.151    0.104    0.081    0.0    0.0   0.046   0.151  \n",
      "TN          0.454    0.349    0.396    0.419    0.5    0.5   0.454   0.349  \n",
      "TP          0.361    0.475    0.429    0.432    0.5    0.5   0.361   0.475  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.040  0.127  0.082  0.078   0.129   0.037    0.085    0.059   \n",
      "FP        0.199  0.043  0.088  0.081   0.051   0.155    0.085    0.090   \n",
      "TN        0.301  0.457  0.412  0.419   0.449   0.345    0.415    0.410   \n",
      "TP        0.460  0.373  0.418  0.422   0.371   0.463    0.415    0.441   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.081    0.078  0.082  0.059  0.129  0.026   0.129   0.030   \n",
      "FP          0.089    0.073  0.088  0.090  0.051  0.148   0.051   0.139   \n",
      "TN          0.411    0.427  0.412  0.410  0.449  0.352   0.449   0.361   \n",
      "TP          0.419    0.422  0.418  0.441  0.371  0.474   0.371   0.470   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.129    0.026    0.082    0.075    0.0    0.0   0.129   0.026  \n",
      "FP          0.051    0.148    0.088    0.074    0.0    0.0   0.051   0.148  \n",
      "TN          0.449    0.352    0.412    0.426    0.5    0.5   0.449   0.352  \n",
      "TP          0.371    0.474    0.418    0.425    0.5    0.5   0.371   0.474  \n"
     ]
    }
   ],
   "source": [
    "# Ratios\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts(normalize=True)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Ratio'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Ratio']\n",
    "    df = df.fillna(0)\n",
    "    df = df.round(decimals = 3)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         786.0  1793.0  1639.0  1090.0  2739.0   508.0   1749.0    856.0   \n",
      "FP        4168.0   666.0  1852.0  1189.0  1007.0  2290.0   1721.0   1294.0   \n",
      "TN        6033.0  6554.0  8349.0  6031.0  9194.0  4930.0   8480.0   5926.0   \n",
      "TP        9415.0  5427.0  8562.0  6130.0  7462.0  6712.0   8452.0   6364.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN         1625.0   1103.0  1681.0   820.0  2739.0   365.0  2739.0   365.0   \n",
      "FP         1876.0   1074.0  1794.0  1342.0  1007.0  2203.0  1007.0  2203.0   \n",
      "TN         8325.0   6146.0  8407.0  5878.0  9194.0  5017.0  9194.0  5017.0   \n",
      "TP         8576.0   6117.0  8520.0  6400.0  7462.0  6855.0  7462.0  6855.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW    testB   testW  unmitB  unmitW  \n",
      "Category                                                                       \n",
      "FN         2739.0    365.0   1625.0    955.0      0.0     0.0  2739.0   365.0  \n",
      "FP         1007.0   2203.0   1876.0   1207.0      0.0     0.0  1007.0  2203.0  \n",
      "TN         9194.0   5017.0   8325.0   6013.0  10201.0  7220.0  9194.0  5017.0  \n",
      "TP         7462.0   6855.0   8576.0   6265.0  10201.0  7220.0  7462.0  6855.0  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         721.0  1654.0  1580.0  1046.0  3901.0   482.0   1708.0    789.0   \n",
      "FP        4347.0   700.0  2064.0  1287.0   581.0  2759.0   1888.0   1365.0   \n",
      "TN        5854.0  6520.0  8137.0  5933.0  9620.0  4461.0   8313.0   5855.0   \n",
      "TP        9480.0  5566.0  8621.0  6174.0  6300.0  6738.0   8493.0   6431.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN         1575.0   1028.0  2293.0   429.0  3946.0   228.0  3796.0    99.0   \n",
      "FP         1993.0   1170.0  1228.0  2010.0   564.0  2866.0   602.0  4344.0   \n",
      "TN         8208.0   6050.0  8973.0  5210.0  9637.0  4354.0  9599.0  2876.0   \n",
      "TP         8626.0   6192.0  7908.0  6791.0  6255.0  6992.0  6405.0  7121.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW    testB   testW  unmitB  unmitW  \n",
      "Category                                                                       \n",
      "FN         3946.0    228.0   1811.0    461.0      0.0     0.0  3946.0   228.0  \n",
      "FP          564.0   2866.0   1660.0   1924.0      0.0     0.0   564.0  2866.0  \n",
      "TN         9637.0   4354.0   8541.0   5296.0  10201.0  7220.0  9637.0  4354.0  \n",
      "TP         6255.0   6992.0   8390.0   6759.0  10201.0  7220.0  6255.0  6992.0  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         789.0  1773.0  1710.0  1117.0  2836.0   595.0   1745.0    830.0   \n",
      "FP        4165.0   647.0  2129.0  1362.0   939.0  2097.0   1813.0   1313.0   \n",
      "TN        6036.0  6573.0  8072.0  5858.0  9262.0  5123.0   8388.0   5907.0   \n",
      "TP        9412.0  5447.0  8491.0  6103.0  7365.0  6625.0   8456.0   6390.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN         1458.0    986.0  1529.0   830.0  2833.0   364.0  2833.0   364.0   \n",
      "FP         2120.0   1168.0  2020.0  1318.0   942.0  2177.0   942.0  2177.0   \n",
      "TN         8081.0   6052.0  8181.0  5902.0  9259.0  5043.0  9259.0  5043.0   \n",
      "TP         8743.0   6234.0  8672.0  6390.0  7368.0  6856.0  7368.0  6856.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW    testB   testW  unmitB  unmitW  \n",
      "Category                                                                       \n",
      "FN         2833.0    364.0   1458.0    983.0      0.0     0.0  2833.0   364.0  \n",
      "FP          942.0   2177.0   2120.0   1171.0      0.0     0.0   942.0  2177.0  \n",
      "TN         9259.0   5043.0   8081.0   6049.0  10201.0  7220.0  9259.0  5043.0  \n",
      "TP         7368.0   6856.0   8743.0   6237.0  10201.0  7220.0  7368.0  6856.0  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         812.0  1830.0  1681.0  1132.0  2640.0   529.0   1738.0    855.0   \n",
      "FP        4056.0   614.0  1794.0  1166.0  1042.0  2233.0   1739.0   1296.0   \n",
      "TN        6145.0  6606.0  8407.0  6054.0  9159.0  4987.0   8462.0   5924.0   \n",
      "TP        9389.0  5390.0  8520.0  6088.0  7561.0  6691.0   8463.0   6365.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN         1658.0   1133.0  1681.0   856.0  2640.0   382.0  2640.0   429.0   \n",
      "FP         1820.0   1058.0  1794.0  1294.0  1042.0  2130.0  1042.0  2010.0   \n",
      "TN         8381.0   6162.0  8407.0  5926.0  9159.0  5090.0  9159.0  5210.0   \n",
      "TP         8543.0   6087.0  8520.0  6364.0  7561.0  6838.0  7561.0  6791.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW    testB   testW  unmitB  unmitW  \n",
      "Category                                                                       \n",
      "FN         2640.0    382.0   1681.0   1090.0      0.0     0.0  2640.0   382.0  \n",
      "FP         1042.0   2130.0   1794.0   1071.0      0.0     0.0  1042.0  2130.0  \n",
      "TN         9159.0   5090.0   8407.0   6149.0  10201.0  7220.0  9159.0  5090.0  \n",
      "TP         7561.0   6838.0   8520.0   6130.0  10201.0  7220.0  7561.0  6838.0  \n"
     ]
    }
   ],
   "source": [
    "# Absolute numbers\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts()\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Number'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Number']\n",
    "    df = df.fillna(0)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_absolute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractig Scores from csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       testB  testW  unmitB  unmitW  egdpB  egdpW  egeoB  egeoW  egtprpB  \\\n",
      "0        728  746.0     803   821.0    803  821.0    803  821.0      803   \n",
      "1        576  355.0     651   355.0    651  355.0    651  355.0      651   \n",
      "2        664  758.0     739   833.0    739  833.0    739  833.0      739   \n",
      "3        626  552.0     701   627.0    701  552.0    701  552.0      701   \n",
      "4        406  767.0     406   842.0    406  842.0    406  842.0      406   \n",
      "...      ...    ...     ...     ...    ...    ...    ...    ...      ...   \n",
      "20397    676    NaN     751     NaN    751    NaN    751    NaN      751   \n",
      "20398    664    NaN     739     NaN    739    NaN    739    NaN      739   \n",
      "20399    560    NaN     560     NaN    635    NaN    635    NaN      635   \n",
      "20400    608    NaN     683     NaN    683    NaN    683    NaN      683   \n",
      "20401    468    NaN     468     NaN    543    NaN    468    NaN      468   \n",
      "\n",
      "       egtprpW  egfprpB  egfprpW  egerpB  egerpW  gsdpB  gsdpW  gseoB  gseoW  \\\n",
      "0        821.0      803    821.0     803   821.0    803  821.0    803  821.0   \n",
      "1        355.0      651    355.0     651   355.0    651  355.0    651  355.0   \n",
      "2        833.0      739    833.0     739   833.0    739  833.0    739  833.0   \n",
      "3        552.0      701    552.0     701   627.0    701  552.0    701  627.0   \n",
      "4        842.0      406    842.0     406   842.0    406  842.0    406  842.0   \n",
      "...        ...      ...      ...     ...     ...    ...    ...    ...    ...   \n",
      "20397      NaN      751      NaN     751     NaN    751    NaN    751    NaN   \n",
      "20398      NaN      739      NaN     739     NaN    739    NaN    739    NaN   \n",
      "20399      NaN      635      NaN     560     NaN    635    NaN    560    NaN   \n",
      "20400      NaN      683      NaN     683     NaN    683    NaN    683    NaN   \n",
      "20401      NaN      468      NaN     468     NaN    468    NaN    468    NaN   \n",
      "\n",
      "       gstprpB  gstprpW  gsfprpB  gsfprpW  gserpB  gserpW  \n",
      "0          803    821.0      803    821.0     803   821.0  \n",
      "1          651    355.0      651    355.0     651   355.0  \n",
      "2          739    833.0      739    833.0     739   833.0  \n",
      "3          701    552.0      701    627.0     701   627.0  \n",
      "4          406    842.0      406    842.0     406   842.0  \n",
      "...        ...      ...      ...      ...     ...     ...  \n",
      "20397      751      NaN      751      NaN     751     NaN  \n",
      "20398      739      NaN      739      NaN     739     NaN  \n",
      "20399      635      NaN      560      NaN     560     NaN  \n",
      "20400      683      NaN      683      NaN     683     NaN  \n",
      "20401      468      NaN      468      NaN     468     NaN  \n",
      "\n",
      "[20402 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scores Data Frames\n",
    "classifier_dfs = {}\n",
    "dfs_b = {}\n",
    "dfs_w = {}\n",
    "dfs_eg = {}\n",
    "dfs_gs = {}\n",
    "for f in folders:\n",
    "    path = f'{data_path}{f}/{f}_all_scores.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    df_black = df.filter(like='B')\n",
    "    df_white = df.filter(like='W')\n",
    "    df_eg = pd.concat([df.iloc[:,:4],df.filter(like='eg')],axis=1)\n",
    "    df_gs = pd.concat([df.iloc[:,:4],df.filter(like='gs')],axis=1)\n",
    "    \n",
    "    classifier_dfs[f] = df\n",
    "    dfs_b[f] = df_black\n",
    "    dfs_w[f] = df_white\n",
    "    dfs_eg[f] = df_eg\n",
    "    dfs_gs[f] = df_gs\n",
    "print(classifier_dfs['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if normal distributions:\n",
    "\n",
    "if p < 0.01 (or < 0.05) then the distribution is significantly different from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dt\n",
      "Check for norm Distributions done\n",
      "Classifier: gnb\n",
      "Check for norm Distributions done\n",
      "Classifier: lgr\n",
      "Check for norm Distributions done\n",
      "Classifier: gbt\n",
      "Check for norm Distributions done\n"
     ]
    }
   ],
   "source": [
    "for c,df in classifier_dfs.items():\n",
    "    print('Classifier:',c)\n",
    "    for col in df:\n",
    "        data=df[col].dropna(axis=0)\n",
    "        _,p = stats.kstest(data, \"norm\")\n",
    "        if p > 0.01:\n",
    "            print(col,',p:',p)\n",
    "    print('Check for norm Distributions done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann Whitney U test:\n",
    "\n",
    "“a two-sample rank test for the difference between two population medians . . . It assumes that the data are independent random samples from two populations that have the same shape.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_path = f'{data_path}mwu/'\n",
    "os.makedirs(mwu_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions EG vs. GS\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dt gnb lgr gbt\n",
      "Constraints               \n",
      "stB                       \n",
      "stW                       \n",
      "mitB                      \n",
      "mitW                      \n",
      "dpB          s   s   s   s\n",
      "dpW          s   s   s   s\n",
      "eoB          s   s   s   s\n",
      "eoW          s   s   s   s\n",
      "tprpB            s        \n",
      "tprpW            s        \n",
      "fprpB        s   s   s   s\n",
      "fprpW        s   s   s   s\n",
      "erpB                      \n",
      "erpW             s        \n"
     ]
    }
   ],
   "source": [
    "p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "for (c1,df_eg),(c2,df_gs) in zip(dfs_eg.items(),dfs_gs.items()):\n",
    "    col_signi = []\n",
    "    col_vals = []\n",
    "    idx = []\n",
    "    \n",
    "    for col_eg,col_gs in zip(df_eg,df_gs):\n",
    "        \n",
    "        idx.append(col_eg[2:])\n",
    "        \n",
    "        data_eg=df_eg[col_eg].dropna(axis=0)\n",
    "        data_gs=df_gs[col_gs].dropna(axis=0)\n",
    "        \n",
    "        _,p = stats.mannwhitneyu(data_eg, data_gs)\n",
    "        \n",
    "        col_vals.append(p)\n",
    "        if p< 0.05:\n",
    "            col_signi.append('s')\n",
    "        else:\n",
    "            col_signi.append(' ')\n",
    "            \n",
    "    p_signi[c1] = col_signi\n",
    "    p_vals[c1] = col_vals\n",
    "    \n",
    "p_vals['Constraints'] = idx\n",
    "p_vals = p_vals.set_index('Constraints')\n",
    "p_signi['Constraints'] = idx\n",
    "p_signi = p_signi.set_index('Constraints')\n",
    "\n",
    "p_vals = p_vals.round(decimals=3)\n",
    "print(p_signi)\n",
    "    \n",
    "p_vals.to_csv(f'{mwu_path}p_eg_gs.csv')\n",
    "p_signi.to_csv(f'{mwu_path}significanz_eg_gs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions Each Model against each other\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_values_mwu_1model(dfs,model=''):\n",
    "    p_vals = pd.DataFrame(data={'Classifier': []})\n",
    "    p_signi = pd.DataFrame(data={'Classifier': []})\n",
    "    \n",
    "    for c1,df1 in dfs.items():\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data1 = df1[model].dropna(axis=0)\n",
    "        \n",
    "        for c2,df2 in dfs.items():\n",
    "            idx.append(c2)\n",
    "            \n",
    "            data2 =df2[model].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data1, data2)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c1] = col_signi\n",
    "        p_vals[c1] = col_vals\n",
    "        \n",
    "    p_vals['Classifier'] = idx\n",
    "    p_vals = p_vals.set_index('Classifier')\n",
    "    p_signi['Classifier'] = idx\n",
    "    p_signi = p_signi.set_index('Classifier')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_{model}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: testB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: testW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: unmitW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: egdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                     s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                     s\n",
      "gbt                 s    \n",
      "\n",
      "C: egtprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                     s\n",
      "gbt                 s    \n",
      "\n",
      "C: egtprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: egerpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gseoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: gseoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gstprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                 s    \n",
      "lgr             s       s\n",
      "gbt                 s    \n",
      "\n",
      "C: gstprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: gsfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gserpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s           s\n",
      "lgr                      \n",
      "gbt             s        \n",
      "\n",
      "C: gserpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n"
     ]
    }
   ],
   "source": [
    "for col in classifier_dfs['dt']:\n",
    "    print('\\nC:',col)\n",
    "    p_values_mwu_1model(classifier_dfs,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions unmitigated v Mitigated for each race\n",
    "\n",
    "if p < 0.001 (or < 0.0005) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_race_mwu(dfs, b_or_w = 'B'):\n",
    "    p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "    p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "    for c,df in dfs.items():\n",
    "        \n",
    "        c = f'{c}{b_or_w}'\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data_unmiti = df[f'unmit{b_or_w}'].dropna(axis=0)\n",
    "        \n",
    "        for col in df:\n",
    "            \n",
    "            idx.append(col[:-1])\n",
    "            \n",
    "            data_miti=df[col].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data_unmiti, data_miti)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c] = col_signi\n",
    "        p_vals[c] = col_vals\n",
    "        \n",
    "    p_vals['Constraints'] = idx\n",
    "    p_vals = p_vals.set_index('Constraints')\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_signi['Constraints'] = idx\n",
    "    p_signi = p_signi.set_index('Constraints')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_un_vs_miti_{b_or_w}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_un_vs_miti_{b_or_w}.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:\n",
      "            dtB gnbB lgrB gbtB\n",
      "Constraints                   \n",
      "test          s    s    s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo          s    s    s    s\n",
      "egtprp        s    s    s    s\n",
      "egfprp        s    s    s    s\n",
      "egerp                         \n",
      "gsdp          s    s    s    s\n",
      "gseo                          \n",
      "gstprp        s    s    s    s\n",
      "gsfprp                        \n",
      "gserp                         \n",
      "\n",
      "White:\n",
      "            dtW gnbW lgrW gbtW\n",
      "Constraints                   \n",
      "test          s    s    s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo          s    s    s    s\n",
      "egtprp        s    s    s    s\n",
      "egfprp        s    s    s    s\n",
      "egerp                         \n",
      "gsdp          s    s    s    s\n",
      "gseo                          \n",
      "gstprp        s    s    s    s\n",
      "gsfprp                        \n",
      "gserp              s          \n"
     ]
    }
   ],
   "source": [
    "print('Black:')\n",
    "p_race_mwu(dfs_b,'B')\n",
    "\n",
    "print('\\nWhite:')\n",
    "p_race_mwu(dfs_w,'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(data_unmiti, data_miti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
