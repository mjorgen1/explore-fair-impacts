{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/results/test_5_unbalanced_seed42/'\n",
    "folders= ['dt','gnb','lgr','gbt']\n",
    "#folders= ['dt','gnb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_csvs(data_path= 'data/results/',b_or_w = 'Black', folders= ['dt','gnb','lgr','gbt']):\n",
    "\n",
    "    col_names_eg = []\n",
    "    col_names_gs = []\n",
    "\n",
    "    for i,f in enumerate(folders):\n",
    "        if b_or_w == 'Black':\n",
    "            path = f'{data_path}{f}/{f}_black_results.csv'\n",
    "        else:\n",
    "            path = f'{data_path}{f}/{f}_white_results.csv'\n",
    "\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        col_names_eg.append(f'EG+{f.upper()}')\n",
    "        col_names_gs.append(f'GS+{f.upper()}')\n",
    "\n",
    "        if i == 0:\n",
    "            joined_df = df.iloc[:,-1]\n",
    "        else:\n",
    "            joined_df = pd.concat([joined_df, df.iloc[:,-1]], axis=1)\n",
    "\n",
    "    joined_df.set_axis(folders, axis=1)\n",
    "\n",
    "\n",
    "    # split dataframe after the two reduction algorithms\n",
    "    df_eg = joined_df.iloc[:6,:]\n",
    "    df_gs = pd.concat([joined_df.iloc[0:1,:],joined_df.iloc[6:,:]])\n",
    "\n",
    "    # set new index\n",
    "    df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_eg.set_index('Constraint',inplace=True)\n",
    "    df_gs['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
    "    df_gs.set_index('Constraint',inplace=True)\n",
    "    df_eg.columns = col_names_eg\n",
    "    df_gs.columns = col_names_gs\n",
    "\n",
    "    df_final = pd.concat([df_eg, df_gs], axis=1)\n",
    "    print('Group: ',b_or_w,'\\n DataFrame: \\n',df_final)\n",
    "    print('A')\n",
    "    df_final.to_csv(f'{data_path}/{b_or_w}_DI.csv')\n",
    "    print('B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  Black \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated   5.55    0.00    7.16    5.64   5.55    0.00    7.16    5.64\n",
      "DP          -39.09  -38.60  -39.62  -39.58 -53.67    0.00  -53.67  -53.67\n",
      "EO           -6.94  -10.55   -7.28   -4.09   5.55  -15.26    7.16    5.64\n",
      "EOO         -17.90  -22.17  -19.66  -17.06 -32.25  -22.62  -30.22  -33.17\n",
      "FPER         -4.06  -17.61   -6.08   -4.36   5.55    0.00    7.16    5.64\n",
      "ERP           5.55    7.23    7.33    5.60   5.55    8.41    7.29    5.64\n",
      "A\n",
      "B\n",
      "Group:  White \n",
      " DataFrame: \n",
      "              EG+DT  EG+GNB  EG+LGR  EG+GBT  GS+DT  GS+GNB  GS+LGR  GS+GBT\n",
      "Constraint                                                               \n",
      "Unmitigated  38.71   36.55   38.22   38.80  38.71   36.55   38.22   38.80\n",
      "DP           39.08   39.01   38.84   39.08  39.21   36.55   39.24   39.24\n",
      "EO           36.98   35.95   36.76   37.27  38.71   23.16   38.22   38.80\n",
      "EOO          39.07   38.84   39.02   39.14  39.21   38.80   39.24   39.19\n",
      "FPER         39.08   38.21   38.77   39.08  38.71   36.55   38.22   38.80\n",
      "ERP          35.75   37.20   35.52   35.84  38.71   30.00   37.94   38.80\n",
      "A\n",
      "B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_10244\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n",
      "C:\\Users\\HaRi\\AppData\\Local\\Temp\\ipykernel_10244\\620886726.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eg['Constraint'] = ['Unmitigated', 'DP', 'EO', 'EOO','FPER','ERP']\n"
     ]
    }
   ],
   "source": [
    "impact_csvs(data_path,'Black', folders= ['dt','gnb','lgr','gbt'])\n",
    "impact_csvs(data_path,'White', folders= ['dt','gnb','lgr','gbt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FP/TP/TN/FN Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.012  0.052  0.044  0.084   0.085   0.080    0.048    0.052   \n",
      "FP        0.442  0.063  0.191  0.064   0.086   0.075    0.169    0.063   \n",
      "TN        0.220  0.177  0.471  0.176   0.576   0.165    0.493    0.177   \n",
      "TP        0.327  0.708  0.295  0.676   0.254   0.680    0.291    0.708   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.029    0.052  0.000  0.081  0.085  0.045   0.085   0.045   \n",
      "FP          0.272    0.063  0.662  0.048  0.086  0.070   0.086   0.070   \n",
      "TN          0.389    0.177  0.000  0.192  0.576  0.171   0.576   0.171   \n",
      "TP          0.309    0.708  0.338  0.678  0.254  0.715   0.254   0.715   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.085    0.045    0.016    0.081  0.000   0.00   0.085   0.045  \n",
      "FP          0.086    0.070    0.380    0.048  0.000   0.00   0.086   0.070  \n",
      "TN          0.576    0.171    0.281    0.192  0.662   0.24   0.576   0.171  \n",
      "TP          0.254    0.715    0.323    0.678  0.338   0.76   0.254   0.715  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.017  0.052  0.038  0.075   0.102   0.107    0.140    0.043   \n",
      "FP        0.452  0.064  0.217  0.074   0.066   0.050    0.214    0.074   \n",
      "TN        0.210  0.176  0.445  0.166   0.595   0.190    0.448    0.166   \n",
      "TP        0.321  0.708  0.301  0.685   0.237   0.653    0.199    0.717   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.023    0.049  0.338  0.028  0.030  0.001   0.117   0.011   \n",
      "FP          0.302    0.067  0.000  0.092  0.252  0.207   0.050   0.145   \n",
      "TN          0.360    0.173  0.662  0.148  0.410  0.034   0.611   0.095   \n",
      "TP          0.316    0.711  0.000  0.732  0.308  0.758   0.221   0.749   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.338    0.028    0.021    0.047  0.000   0.00   0.338   0.028  \n",
      "FP          0.000    0.092    0.306    0.068  0.000   0.00   0.000   0.092  \n",
      "TN          0.662    0.148    0.356    0.172  0.662   0.24   0.662   0.148  \n",
      "TP          0.000    0.732    0.318    0.713  0.338   0.76   0.000   0.732  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.008  0.047  0.041  0.083   0.102   0.089    0.042    0.045   \n",
      "FP        0.444  0.068  0.193  0.064   0.065   0.069    0.185    0.069   \n",
      "TN        0.217  0.173  0.468  0.176   0.596   0.171    0.477    0.171   \n",
      "TP        0.330  0.713  0.297  0.677   0.237   0.671    0.296    0.715   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.026    0.055  0.000  0.083  0.098  0.039   0.102   0.037   \n",
      "FP          0.283    0.063  0.662  0.047  0.068  0.076   0.066   0.079   \n",
      "TN          0.378    0.177  0.000  0.193  0.593  0.164   0.596   0.161   \n",
      "TP          0.312    0.705  0.338  0.677  0.240  0.721   0.237   0.723   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.098    0.039    0.014    0.083  0.000   0.00   0.098   0.039  \n",
      "FP          0.068    0.076    0.360    0.047  0.000   0.00   0.068   0.076  \n",
      "TN          0.593    0.164    0.302    0.193  0.662   0.24   0.593   0.164  \n",
      "TP          0.240    0.721    0.325    0.677  0.338   0.76   0.240   0.721  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID        egdpB  egdpW  egeoB  egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                 \n",
      "FN        0.009  0.052  0.048  0.093   0.083   0.081    0.047    0.052   \n",
      "FP        0.437  0.063  0.169  0.056   0.086   0.074    0.171    0.063   \n",
      "TN        0.225  0.177  0.493  0.184   0.575   0.166    0.491    0.177   \n",
      "TP        0.329  0.708  0.290  0.667   0.255   0.679    0.292    0.708   \n",
      "\n",
      "ID        egtprpB  egtprpW  gsdpB  gsdpW  gseoB  gseoW  gserpB  gserpW  \\\n",
      "Category                                                                 \n",
      "FN          0.031    0.056  0.000  0.083  0.083  0.047   0.083   0.047   \n",
      "FP          0.266    0.061  0.662  0.047  0.086  0.068   0.086   0.068   \n",
      "TN          0.396    0.179  0.000  0.193  0.576  0.172   0.576   0.172   \n",
      "TP          0.307    0.704  0.338  0.677  0.255  0.713   0.255   0.713   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW  testB  testW  unmitB  unmitW  \n",
      "Category                                                                    \n",
      "FN          0.083    0.047    0.016    0.086  0.000   0.00   0.083   0.047  \n",
      "FP          0.086    0.068    0.387    0.046  0.000   0.00   0.086   0.068  \n",
      "TN          0.576    0.172    0.275    0.194  0.662   0.24   0.576   0.172  \n",
      "TP          0.255    0.713    0.323    0.674  0.338   0.76   0.255   0.713  \n"
     ]
    }
   ],
   "source": [
    "# Ratios\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts(normalize=True)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Ratio'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Ratio']\n",
    "    df = df.fillna(0)\n",
    "    df = df.round(decimals = 3)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  dt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         280.0   580.0   475.0   433.0   633.0   368.0    528.0    317.0   \n",
      "FP        1436.0   510.0   793.0   791.0   608.0  1209.0    735.0    825.0   \n",
      "TN        2169.0  3095.0  2812.0  2814.0  2997.0  2396.0   2870.0   2780.0   \n",
      "TP        3325.0  3025.0  3130.0  3172.0  2972.0  3237.0   3077.0   3288.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          475.0    436.0   457.0   347.0   633.0   203.0   633.0   203.0   \n",
      "FP          793.0    668.0   854.0   785.0   608.0  1124.0   608.0  1124.0   \n",
      "TN         2812.0   2937.0  2751.0  2820.0  2997.0  2481.0  2997.0  2481.0   \n",
      "TP         3130.0   3169.0  3148.0  3258.0  2972.0  3402.0  2972.0  3402.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          633.0    203.0    475.0    317.0     0.0     0.0   633.0   203.0  \n",
      "FP          608.0   1124.0    793.0    825.0     0.0     0.0   608.0  1124.0  \n",
      "TN         2997.0   2481.0   2812.0   2780.0  3605.0  3605.0  2997.0  2481.0  \n",
      "TP         2972.0   3402.0   3130.0   3288.0  3605.0  3605.0  2972.0  3402.0  \n",
      "Classifier:  gnb \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         226.0   479.0   443.0   390.0   938.0   319.0    480.0    270.0   \n",
      "FP        1581.0   615.0   923.0   917.0   391.0  1408.0    841.0    937.0   \n",
      "TN        2024.0  2990.0  2682.0  2688.0  3214.0  2197.0   2764.0   2668.0   \n",
      "TP        3379.0  3126.0  3162.0  3215.0  2667.0  3286.0   3125.0   3335.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          418.0    367.0   475.0   216.0  1004.0   105.0   944.0    55.0   \n",
      "FP          997.0    836.0   793.0  1094.0   345.0  1504.0   376.0  2017.0   \n",
      "TN         2608.0   2769.0  2812.0  2511.0  3260.0  2101.0  3229.0  1588.0   \n",
      "TP         3187.0   3238.0  3130.0  3389.0  2601.0  3500.0  2661.0  3550.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN         1004.0    105.0    607.0    137.0     0.0     0.0  1004.0   105.0  \n",
      "FP          345.0   1504.0    629.0   1319.0     0.0     0.0   345.0  1504.0  \n",
      "TN         3260.0   2101.0   2976.0   2286.0  3605.0  3605.0  3260.0  2101.0  \n",
      "TP         2601.0   3500.0   2998.0   3468.0  3605.0  3605.0  2601.0  3500.0  \n",
      "Classifier:  lgr \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         254.0   535.0   458.0   414.0   637.0   380.0    485.0    297.0   \n",
      "FP        1498.0   562.0   846.0   840.0   606.0  1101.0    768.0    874.0   \n",
      "TN        2107.0  3043.0  2759.0  2765.0  2999.0  2504.0   2837.0   2731.0   \n",
      "TP        3351.0  3070.0  3147.0  3191.0  2968.0  3225.0   3120.0   3308.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          430.0    394.0   316.0   415.0   633.0   183.0   633.0    46.0   \n",
      "FP          940.0    829.0  1288.0   688.0   608.0  1174.0   608.0  2126.0   \n",
      "TN         2665.0   2776.0  2317.0  2917.0  2997.0  2431.0  2997.0  1479.0   \n",
      "TP         3175.0   3211.0  3289.0  3190.0  2972.0  3422.0  2972.0  3559.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          633.0    183.0    426.0    305.0     0.0     0.0   633.0   183.0  \n",
      "FP          608.0   1174.0    931.0    852.0     0.0     0.0   608.0  1174.0  \n",
      "TN         2997.0   2431.0   2674.0   2753.0  3605.0  3605.0  2997.0  2431.0  \n",
      "TP         2972.0   3422.0   3179.0   3300.0  3605.0  3605.0  2972.0  3422.0  \n",
      "Classifier:  gbt \n",
      " DataFrame: \n",
      " ID         egdpB   egdpW   egeoB   egeoW  egerpB  egerpW  egfprpB  egfprpW  \\\n",
      "Category                                                                     \n",
      "FN         284.0   585.0   475.0   422.0   633.0   333.0    499.0    305.0   \n",
      "FP        1422.0   503.0   793.0   791.0   608.0  1257.0    752.0    852.0   \n",
      "TN        2183.0  3102.0  2812.0  2814.0  2997.0  2348.0   2853.0   2753.0   \n",
      "TP        3321.0  3020.0  3130.0  3183.0  2972.0  3272.0   3106.0   3300.0   \n",
      "\n",
      "ID        egtprpB  egtprpW   gsdpB   gsdpW   gseoB   gseoW  gserpB  gserpW  \\\n",
      "Category                                                                     \n",
      "FN          475.0    432.0   443.0   360.0   672.0   199.0   633.0   183.0   \n",
      "FP          793.0    672.0   887.0   757.0   580.0  1144.0   608.0  1174.0   \n",
      "TN         2812.0   2933.0  2718.0  2848.0  3025.0  2461.0  2997.0  2431.0   \n",
      "TP         3130.0   3173.0  3162.0  3245.0  2933.0  3406.0  2972.0  3422.0   \n",
      "\n",
      "ID        gsfprpB  gsfprpW  gstprpB  gstprpW   testB   testW  unmitB  unmitW  \n",
      "Category                                                                      \n",
      "FN          672.0    199.0    475.0    318.0     0.0     0.0   672.0   199.0  \n",
      "FP          580.0   1144.0    793.0    826.0     0.0     0.0   580.0  1144.0  \n",
      "TN         3025.0   2461.0   2812.0   2779.0  3605.0  3605.0  3025.0  2461.0  \n",
      "TP         2933.0   3406.0   3130.0   3287.0  3605.0  3605.0  2933.0  3406.0  \n"
     ]
    }
   ],
   "source": [
    "# Absolute numbers\n",
    "dfs = {} # list for pandas dfs\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i,f in enumerate(folders):\n",
    "    path = f'{data_path}{f}/{f}_all_types.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.melt(var_name=\"ID\",value_name=\"Category\")\n",
    "    df = df.groupby('ID').value_counts()\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns= {0:'Number'})\n",
    "    \n",
    "    df = df.pivot(index='Category', columns='ID')['Number']\n",
    "    df = df.fillna(0)\n",
    "    print('Classifier: ',f,'\\n DataFrame: \\n',df)\n",
    "    df.to_csv(f'{data_path}{f}/{f}_type_absolute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractig Scores from csv into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      testB  testW  unmitB  unmitW  egdpB  egdpW  egeoB  egeoW  egtprpB  \\\n",
      "0       605    622     680     697    680    697    680    697      680   \n",
      "1       543    555     393     405    393    555    393    555      393   \n",
      "2       568    502     643     502    643    502    643    502      643   \n",
      "3       632    728     707     803    707    803    707    803      707   \n",
      "4       622    390     472     390    472    390    472    390      472   \n",
      "...     ...    ...     ...     ...    ...    ...    ...    ...      ...   \n",
      "7205    622    434     472     434    472    434    472    434      472   \n",
      "7206    475    483     475     483    475    483    475    483      475   \n",
      "7207    515    565     515     415    365    565    515    565      515   \n",
      "7208    524    464     524     464    374    464    374    464      374   \n",
      "7209    355    456     355     456    355    456    355    456      355   \n",
      "\n",
      "      egtprpW  egfprpB  egfprpW  egerpB  egerpW  gsdpB  gsdpW  gseoB  gseoW  \\\n",
      "0         697      680      697     680     697    680    697    680    697   \n",
      "1         555      393      555     393     405    393    555    393    405   \n",
      "2         502      643      502     643     502    643    502    643    502   \n",
      "3         803      707      803     707     803    707    803    707    803   \n",
      "4         390      472      390     472     390    472    390    472    390   \n",
      "...       ...      ...      ...     ...     ...    ...    ...    ...    ...   \n",
      "7205      434      472      434     472     434    472    434    472    434   \n",
      "7206      483      475      483     475     483    475    483    475    483   \n",
      "7207      565      515      565     515     415    515    565    515    415   \n",
      "7208      464      374      464     524     314    374    464    524    464   \n",
      "7209      456      355      456     355     456    355    456    355    456   \n",
      "\n",
      "      gstprpB  gstprpW  gsfprpB  gsfprpW  gserpB  gserpW  \n",
      "0         680      697      680      697     680     697  \n",
      "1         393      555      393      405     393     405  \n",
      "2         643      502      643      502     643     502  \n",
      "3         707      803      707      803     707     803  \n",
      "4         472      390      472      390     472     390  \n",
      "...       ...      ...      ...      ...     ...     ...  \n",
      "7205      472      434      472      434     472     434  \n",
      "7206      475      483      475      483     475     483  \n",
      "7207      515      565      515      415     515     415  \n",
      "7208      374      464      524      464     524     464  \n",
      "7209      355      456      355      456     355     456  \n",
      "\n",
      "[7210 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scores Data Frames\n",
    "classifier_dfs = {}\n",
    "dfs_b = {}\n",
    "dfs_w = {}\n",
    "dfs_eg = {}\n",
    "dfs_gs = {}\n",
    "for f in folders:\n",
    "    path = f'{data_path}{f}/{f}_all_scores.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    df_black = df.filter(like='B')\n",
    "    df_white = df.filter(like='W')\n",
    "    df_eg = pd.concat([df.iloc[:,:4],df.filter(like='eg')],axis=1)\n",
    "    df_gs = pd.concat([df.iloc[:,:4],df.filter(like='gs')],axis=1)\n",
    "    \n",
    "    classifier_dfs[f] = df\n",
    "    dfs_b[f] = df_black\n",
    "    dfs_w[f] = df_white\n",
    "    dfs_eg[f] = df_eg\n",
    "    dfs_gs[f] = df_gs\n",
    "print(classifier_dfs['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if normal distributions:\n",
    "\n",
    "if p < 0.01 (or < 0.05) then the distribution is significantly different from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dt\n",
      "Check for norm Distributions done\n",
      "Classifier: gnb\n",
      "Check for norm Distributions done\n",
      "Classifier: lgr\n",
      "Check for norm Distributions done\n",
      "Classifier: gbt\n",
      "Check for norm Distributions done\n"
     ]
    }
   ],
   "source": [
    "for c,df in classifier_dfs.items():\n",
    "    print('Classifier:',c)\n",
    "    for col in df:\n",
    "        data=df[col].dropna(axis=0)\n",
    "        _,p = stats.kstest(data, \"norm\")\n",
    "        if p > 0.01:\n",
    "            print(col,',p:',p)\n",
    "    print('Check for norm Distributions done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann Whitney U test:\n",
    "\n",
    "“a two-sample rank test for the difference between two population medians . . . It assumes that the data are independent random samples from two populations that have the same shape.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_path = f'{data_path}mwu/'\n",
    "os.makedirs(mwu_path,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions EG vs. GS\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dt gnb lgr gbt\n",
      "Constraints               \n",
      "stB                       \n",
      "stW                       \n",
      "mitB                      \n",
      "mitW                      \n",
      "dpB          s   s   s   s\n",
      "dpW          s   s       s\n",
      "eoB          s   s   s   s\n",
      "eoW          s   s   s   s\n",
      "tprpB            s        \n",
      "tprpW            s        \n",
      "fprpB            s       s\n",
      "fprpW        s   s   s   s\n",
      "erpB                      \n",
      "erpW             s   s    \n"
     ]
    }
   ],
   "source": [
    "p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "for (c1,df_eg),(c2,df_gs) in zip(dfs_eg.items(),dfs_gs.items()):\n",
    "    col_signi = []\n",
    "    col_vals = []\n",
    "    idx = []\n",
    "    \n",
    "    for col_eg,col_gs in zip(df_eg,df_gs):\n",
    "        \n",
    "        idx.append(col_eg[2:])\n",
    "        \n",
    "        data_eg=df_eg[col_eg].dropna(axis=0)\n",
    "        data_gs=df_gs[col_gs].dropna(axis=0)\n",
    "        \n",
    "        _,p = stats.mannwhitneyu(data_eg, data_gs)\n",
    "        \n",
    "        col_vals.append(p)\n",
    "        if p< 0.05:\n",
    "            col_signi.append('s')\n",
    "        else:\n",
    "            col_signi.append(' ')\n",
    "            \n",
    "    p_signi[c1] = col_signi\n",
    "    p_vals[c1] = col_vals\n",
    "    \n",
    "p_vals['Constraints'] = idx\n",
    "p_vals = p_vals.set_index('Constraints')\n",
    "p_signi['Constraints'] = idx\n",
    "p_signi = p_signi.set_index('Constraints')\n",
    "\n",
    "p_vals = p_vals.round(decimals=3)\n",
    "print(p_signi)\n",
    "    \n",
    "p_vals.to_csv(f'{mwu_path}p_eg_gs.csv')\n",
    "p_signi.to_csv(f'{mwu_path}significanz_eg_gs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions Each Model against each other\n",
    "if p < 0.001 (or < 0.05) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_values_mwu_1model(dfs,model=''):\n",
    "    p_vals = pd.DataFrame(data={'Classifier': []})\n",
    "    p_signi = pd.DataFrame(data={'Classifier': []})\n",
    "    \n",
    "    for c1,df1 in dfs.items():\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data1 = df1[model].dropna(axis=0)\n",
    "        \n",
    "        for c2,df2 in dfs.items():\n",
    "            idx.append(c2)\n",
    "            \n",
    "            data2 =df2[model].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data1, data2)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c1] = col_signi\n",
    "        p_vals[c1] = col_vals\n",
    "        \n",
    "    p_vals['Classifier'] = idx\n",
    "    p_vals = p_vals.set_index('Classifier')\n",
    "    p_signi['Classifier'] = idx\n",
    "    p_signi = p_signi.set_index('Classifier')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_{model}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: testB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: testW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: unmitW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: egdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egeoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egtprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egtprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: egerpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gsdpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                  s    \n",
      "gnb                 s    \n",
      "lgr         s   s       s\n",
      "gbt                 s    \n",
      "\n",
      "C: gsdpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gseoB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gseoW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gstprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                 s    \n",
      "lgr             s        \n",
      "gbt                      \n",
      "\n",
      "C: gstprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gsfprpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gsfprpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s        \n",
      "gnb         s       s   s\n",
      "lgr             s        \n",
      "gbt             s        \n",
      "\n",
      "C: gserpB\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt                       \n",
      "gnb                      \n",
      "lgr                      \n",
      "gbt                      \n",
      "\n",
      "C: gserpW\n",
      "           dt gnb lgr gbt\n",
      "Classifier               \n",
      "dt              s   s    \n",
      "gnb         s           s\n",
      "lgr         s           s\n",
      "gbt             s   s    \n"
     ]
    }
   ],
   "source": [
    "for col in classifier_dfs['dt']:\n",
    "    print('\\nC:',col)\n",
    "    p_values_mwu_1model(classifier_dfs,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of Distributions unmitigated v Mitigated for each race\n",
    "\n",
    "if p < 0.001 (or < 0.0005) then the distributions are significantly different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_race_mwu(dfs, b_or_w = 'B'):\n",
    "    p_vals = pd.DataFrame(data={'Constraints': []})\n",
    "    p_signi = pd.DataFrame(data={'Constraints': []})\n",
    "    \n",
    "    for c,df in dfs.items():\n",
    "        \n",
    "        c = f'{c}{b_or_w}'\n",
    "        col_signi = []\n",
    "        col_vals = []\n",
    "        idx = []\n",
    "        \n",
    "        data_unmiti = df[f'unmit{b_or_w}'].dropna(axis=0)\n",
    "        \n",
    "        for col in df:\n",
    "            \n",
    "            idx.append(col[:-1])\n",
    "            \n",
    "            data_miti=df[col].dropna(axis=0)\n",
    "            \n",
    "            _,p = stats.mannwhitneyu(data_unmiti, data_miti)\n",
    "            \n",
    "            col_vals.append(p)\n",
    "            if p< 0.05:\n",
    "                col_signi.append('s')\n",
    "            else:\n",
    "                col_signi.append(' ')\n",
    "                \n",
    "        p_signi[c] = col_signi\n",
    "        p_vals[c] = col_vals\n",
    "        \n",
    "    p_vals['Constraints'] = idx\n",
    "    p_vals = p_vals.set_index('Constraints')\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_signi['Constraints'] = idx\n",
    "    p_signi = p_signi.set_index('Constraints')\n",
    "    \n",
    "    p_vals = p_vals.round(decimals=3)\n",
    "    print(p_signi)\n",
    "    \n",
    "    p_vals.to_csv(f'{mwu_path}p_un_vs_miti_{b_or_w}.csv')\n",
    "    p_signi.to_csv(f'{mwu_path}significanz_un_vs_miti_{b_or_w}.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:\n",
      "            dtB gnbB lgrB gbtB\n",
      "Constraints                   \n",
      "test          s    s    s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo               s          \n",
      "egtprp             s    s     \n",
      "egfprp             s          \n",
      "egerp                         \n",
      "gsdp               s    s    s\n",
      "gseo                          \n",
      "gstprp             s    s     \n",
      "gsfprp                        \n",
      "gserp                         \n",
      "\n",
      "White:\n",
      "            dtW gnbW lgrW gbtW\n",
      "Constraints                   \n",
      "test          s         s    s\n",
      "unmit                         \n",
      "egdp          s    s    s    s\n",
      "egeo               s         s\n",
      "egtprp        s    s         s\n",
      "egfprp        s    s    s    s\n",
      "egerp                         \n",
      "gsdp          s    s    s    s\n",
      "gseo                          \n",
      "gstprp        s         s    s\n",
      "gsfprp                        \n",
      "gserp              s    s     \n"
     ]
    }
   ],
   "source": [
    "print('Black:')\n",
    "p_race_mwu(dfs_b,'B')\n",
    "\n",
    "print('\\nWhite:')\n",
    "p_race_mwu(dfs_w,'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_unmiti' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stats\u001b[38;5;241m.\u001b[39mpearsonr(\u001b[43mdata_unmiti\u001b[49m, data_miti)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_unmiti' is not defined"
     ]
    }
   ],
   "source": [
    "stats.pearsonr(data_unmiti, data_miti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
